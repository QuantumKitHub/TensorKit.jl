<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Constructing tensors and the TensorMap type ¬∑ TensorKit.jl</title><meta name="title" content="Constructing tensors and the TensorMap type ¬∑ TensorKit.jl"/><meta property="og:title" content="Constructing tensors and the TensorMap type ¬∑ TensorKit.jl"/><meta property="twitter:title" content="Constructing tensors and the TensorMap type ¬∑ TensorKit.jl"/><meta name="description" content="Documentation for TensorKit.jl."/><meta property="og:description" content="Documentation for TensorKit.jl."/><meta property="twitter:description" content="Documentation for TensorKit.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/custom.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img class="docs-light-only" src="../../assets/logo.svg" alt="TensorKit.jl logo"/><img class="docs-dark-only" src="../../assets/logo-dark.svg" alt="TensorKit.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">TensorKit.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Manual</span><ul><li><a class="tocitem" href="../intro/">Introduction</a></li><li><a class="tocitem" href="../tutorial/">Tutorial</a></li><li><a class="tocitem" href="../spaces/">Vector spaces</a></li><li><a class="tocitem" href="../symmetries/">Symmetries</a></li><li><a class="tocitem" href="../sectors/">Sectors</a></li><li><a class="tocitem" href="../gradedspaces/">Graded spaces</a></li><li><a class="tocitem" href="../fusiontrees/">Fusion trees</a></li><li class="is-active"><a class="tocitem" href>Constructing tensors and the <code>TensorMap</code> type</a><ul class="internal"><li><a class="tocitem" href="#ss_tensor_storage"><span>Storage of tensor data</span></a></li><li><a class="tocitem" href="#ss_tensor_construction"><span>Constructing tensor maps and accessing tensor data</span></a></li><li><a class="tocitem" href="#ss_tensor_properties"><span>Tensor properties</span></a></li><li><a class="tocitem" href="#ss_tensor_readwrite"><span>Reading and writing tensors: <code>Dict</code> conversion</span></a></li></ul></li><li><a class="tocitem" href="../tensormanipulations/">Manipulating tensors</a></li></ul></li><li><span class="tocitem">Library</span><ul><li><a class="tocitem" href="../../lib/sectors/">Symmetry sectors</a></li><li><a class="tocitem" href="../../lib/fusiontrees/">Fusion trees</a></li><li><a class="tocitem" href="../../lib/spaces/">Vector spaces</a></li><li><a class="tocitem" href="../../lib/tensors/">Tensors</a></li></ul></li><li><span class="tocitem">Index</span><ul><li><a class="tocitem" href="../../index/">Index</a></li></ul></li><li><span class="tocitem">Appendix</span><ul><li><a class="tocitem" href="../../appendix/symmetric_tutorial/">A symmetric tensor deep dive: constructing your first tensor map</a></li><li><a class="tocitem" href="../../appendix/categories/">Optional introduction to category theory</a></li></ul></li><li><a class="tocitem" href="../../Changelog/">Changelog</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Manual</a></li><li class="is-active"><a href>Constructing tensors and the <code>TensorMap</code> type</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Constructing tensors and the <code>TensorMap</code> type</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/QuantumKitHub/TensorKit.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands">ÔÇõ</span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/QuantumKitHub/TensorKit.jl/blob/main/docs/src/man/tensors.md" title="Edit source on GitHub"><span class="docs-icon fa-solid">ÔÅÑ</span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="s_tensors"><a class="docs-heading-anchor" href="#s_tensors">Constructing tensors and the <code>TensorMap</code> type</a><a id="s_tensors-1"></a><a class="docs-heading-anchor-permalink" href="#s_tensors" title="Permalink"></a></h1><p>This last page explains how to create and manipulate tensors in TensorKit.jl. As this is probably the most important part of the manual, we will also focus more strongly on the usage and interface, and less so on the underlying implementation. The only aspect of the implementation that we will address is the storage of the tensor data, as this is important to know how to create and initialize a tensor, but will in fact also shed light on how some of the methods work.</p><p>As mentioned, all tensors in TensorKit.jl are interpreted as linear maps (morphisms) from a domain (a <code>ProductSpace{S, N‚ÇÇ}</code>) to a codomain (another <code>ProductSpace{S, N‚ÇÅ}</code>), with the same <code>S &lt;: ElementarySpace</code> that labels the type of spaces associated with the individual tensor indices. The overall type for all such tensor maps is <code>AbstractTensorMap{T, S, N‚ÇÅ, N‚ÇÇ}</code>. Note that we place information about the codomain before that of the domain. Indeed, we have already encountered the constructor for the concrete parametric type <code>TensorMap</code> in the form <code>TensorMap(..., codomain, domain)</code>. This convention is opposite to the mathematical notation, e.g. <span>$\mathrm{Hom}(W, V)$</span> or <span>$f : W ‚Üí V$</span>, but originates from the fact that a normal matrix is also denoted as having size <code>m √ó n</code> or is constructed in Julia as <code>Array(..., (m, n))</code>, where the first integer <code>m</code> refers to the codomain being <code>m</code>- dimensional, and the seond integer <code>n</code> to the domain being <code>n</code>-dimensional. This also explains why we have consistently used the symbol <span>$W$</span> for spaces in the domain and <span>$V$</span> for spaces in the codomain. A tensor map <span>$t : (W_1 ‚äó ‚Ä¶ ‚äó W_{N_2}) ‚Üí (V_1 ‚äó ‚Ä¶ ‚äó V_{N_1})$</span> will be created in Julia as <code>TensorMap(..., V1 ‚äó ... ‚äó VN‚ÇÅ, W1 ‚äó ... ‚äó WN‚ÇÇ)</code>.</p><p>Furthermore, the abstract type <code>AbstractTensor{T, S, N}</code> is just a synonym for <code>AbstractTensorMap{T, S, N, 0}</code>, i.e. for tensor maps with an empty domain, which is equivalent to the unit of the monoidal category, or thus, the field of scalars <span>$ùïú$</span>.</p><p>Currently, <code>AbstractTensorMap</code> has three subtypes. <code>TensorMap</code> provides the actual implementation, where the data of the tensor is stored in a <code>DenseArray</code> (more specifically a <code>DenseMatrix</code> as will be explained below). <code>AdjointTensorMap</code> is a simple wrapper type to denote the adjoint of an existing <code>TensorMap</code> object. <code>DiagonalTensorMap</code> provides an efficient representations of diagonal tensor maps. In the future, additional types could be defined, to deal with sparse data, static data, etc...</p><h2 id="ss_tensor_storage"><a class="docs-heading-anchor" href="#ss_tensor_storage">Storage of tensor data</a><a id="ss_tensor_storage-1"></a><a class="docs-heading-anchor-permalink" href="#ss_tensor_storage" title="Permalink"></a></h2><p>Before discussion how to construct and initalize a <code>TensorMap</code>, let us discuss what is meant by &#39;tensor data&#39; and how it can efficiently and compactly be stored. Let us first discuss the case <code>sectortype(S) == Trivial</code> sector, i.e. the case of no symmetries. In that case the data of a tensor <code>t = TensorMap(..., V1 ‚äó ... ‚äó VN‚ÇÅ, W‚ÇÅ ‚äó ... ‚äó WN‚ÇÇ)</code> can just be represented as a multidimensional array of size</p><pre><code class="language-julia hljs">(dim(V1), dim(V2), ‚Ä¶, dim(VN‚ÇÅ), dim(W1), ‚Ä¶, dim(WN‚ÇÇ))</code></pre><p>which can also be reshaped into matrix of size</p><pre><code class="language-julia hljs">(dim(V1) * dim(V2) * ‚Ä¶ * dim(VN‚ÇÅ), dim(W1) * dim(W2) * ‚Ä¶ * dim(WN‚ÇÇ))</code></pre><p>and is really the matrix representation of the linear map that the tensor represents. In particular, given a second tensor <code>t2</code> whose domain matches with the codomain of <code>t</code>, function composition amounts to multiplication of their corresponding data matrices. Similarly, tensor factorizations such as the singular value decomposition, which we discuss below, can act directly on this matrix representation.</p><div class="admonition is-info" id="Note-a8f5493582e04a6c"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-a8f5493582e04a6c" title="Permalink"></a></header><div class="admonition-body"><p>One might wonder if it would not have been more natural to represent the tensor data as <code>(dim(V1), dim(V2), ‚Ä¶, dim(VN‚ÇÅ), dim(WN‚ÇÇ), ‚Ä¶, dim(W1))</code> given how employing the duality naturally reverses the tensor product, as encountered with the interface of <a href="../../lib/fusiontrees/#TensorKit.repartition-Union{Tuple{N‚ÇÇ}, Tuple{N‚ÇÅ}, Tuple{I}, Tuple{FusionTree{I, N‚ÇÅ}, FusionTree{I, N‚ÇÇ}, Int64}} where {I&lt;:Sector, N‚ÇÅ, N‚ÇÇ}"><code>repartition</code></a> for <a href="@ref ss_fusiontrees">fusion trees</a>. However, such a representation, when plainly <code>reshape</code>d to a matrix, would not have the above properties and would thus not constitute the matrix representation of the tensor in a compatible basis.</p></div></div><p>Now consider the case where <code>sectortype(S) == I</code> for some <code>I</code> which has <code>FusionStyle(I) == UniqueFusion()</code>, i.e. the representations of an Abelian group, e.g. <code>I == Irrep[‚Ñ§‚ÇÇ]</code> or <code>I == Irrep[U‚ÇÅ]</code>. In this case, the tensor data is associated with sectors <code>(a1, a2, ‚Ä¶, aN‚ÇÅ) ‚àà sectors(V1 ‚äó V2 ‚äó ‚Ä¶ ‚äó VN‚ÇÅ)</code> and <code>(b1, ‚Ä¶, bN‚ÇÇ) ‚àà sectors(W1 ‚äó ‚Ä¶ ‚äó WN‚ÇÇ)</code> such that they fuse to a same common charge, i.e.  <code>(c = first(‚äó(a1, ‚Ä¶, aN‚ÇÅ))) == first(‚äó(b1, ‚Ä¶, bN‚ÇÇ))</code>. The data associated with this takes the form of a multidimensional array with size <code>(dim(V1, a1), ‚Ä¶, dim(VN‚ÇÅ, aN‚ÇÅ), dim(W1, b1), ‚Ä¶, dim(WN‚ÇÇ, bN‚ÇÇ))</code>, or equivalently, a matrix of with row size <code>dim(V1, a1) * ‚Ä¶ * dim(VN‚ÇÅ, aN‚ÇÅ) == dim(codomain, (a1, ‚Ä¶, aN‚ÇÅ))</code> and column size <code>dim(W1, b1) * ‚Ä¶ * dim(WN‚ÇÇ, aN‚ÇÇ) == dim(domain, (b1, ‚Ä¶, bN‚ÇÇ))</code>.</p><p>However, there are multiple combinations of <code>(a1, ‚Ä¶, aN‚ÇÅ)</code> giving rise to the same <code>c</code>, and so there is data associated with all of these, as well as all possible combinations of <code>(b1, ‚Ä¶, bN‚ÇÇ)</code>. Stacking all matrices for different <code>(a1, ‚Ä¶)</code> and a fixed value of <code>(b1, ‚Ä¶)</code> underneath each other, and for fixed value of <code>(a1, ‚Ä¶)</code> and different values of <code>(b1, ‚Ä¶)</code> next to each other, gives rise to a larger block matrix of all data associated with the central sector <code>c</code>. The size of this matrix is exactly <code>(blockdim(codomain, c), blockdim(domain, c))</code> and these matrices are exactly the diagonal blocks whose existence is guaranteed by Schur&#39;s lemma, and which are labeled by the coupled sector <code>c</code>. Indeed, if we would represent the tensor map <code>t</code> as a matrix without explicitly using the symmetries, we could reorder the rows and columns to group data corresponding to sectors that fuse to the same <code>c</code>, and the resulting block diagonal representation would emerge. This basis transform is thus a permutation, which is a unitary operation, that will cancel or go through trivially for linear algebra operations such as composing tensor maps (matrix multiplication) or tensor factorizations such as a singular value decomposition. For such linear algebra operations, we can thus directly act on these large matrices, which correspond to the diagonal blocks that emerge after a basis transform, provided that the partition of the tensor indices in domain and codomain of the tensor are in line with our needs. For example, composing two tensor maps amounts to multiplying the matrices corresponding to the same <code>c</code> (provided that its subblocks labeled by the different combinations of sectors are ordered in the same way, which we guarantee by associating a canonical order with sectors). Henceforth, we refer to the <code>blocks</code> of a tensor map as those diagonal blocks, the existence of which is provided by Schur&#39;s lemma and which are labeled by the coupled sectors <code>c</code>. We directly concatenate these blocks as consecutive entries in a single larger <code>DenseVector</code>, together with metadata to retrieve a block by using the corresponding coupled sector <code>c</code> as key. For a given tensor <code>t</code>, we can access a specific block as <code>block(t, c)</code>, whereas <code>blocks(t)</code> yields an iterator over pairs <code>c =&gt; block(t, c)</code>.</p><p>The subblocks corresponding to a particular combination of sectors then correspond to a particular view for some range of the rows and some range of the colums, i.e. <code>view(block(t, c), m‚ÇÅ:m‚ÇÇ, n‚ÇÅ:n‚ÇÇ)</code> where the ranges <code>m‚ÇÅ:m‚ÇÇ</code> associated with <code>(a1, ‚Ä¶, aN‚ÇÅ)</code> and <code>n‚ÇÅ:n‚ÇÇ</code> associated with <code>(b‚ÇÅ, ‚Ä¶, bN‚ÇÇ)</code> are stored within the fields of the instance <code>t</code> of type <code>TensorMap</code>. This <code>view</code> can then lazily be reshaped to a multidimensional array, for which we rely on the package <a href="https://github.com/Jutho/Strided.jl">Strided.jl</a>. Indeed, the data in this <code>view</code> is not contiguous, because the stride between the different columns is larger than the length of the columns. Nonetheless, this does not pose a problem and even as multidimensional array there is still a definite stride associated with each dimension.</p><p>When <code>FusionStyle(I) isa MultipleFusion</code>, things become slightly more complicated. Not only do <code>(a1, ‚Ä¶, aN‚ÇÅ)</code> give rise to different coupled sectors <code>c</code>, there can be multiply ways in which they fuse to <code>c</code>. These different possibilities are enumerated by the iterator <code>fusiontrees((a1, ‚Ä¶, aN‚ÇÅ), c)</code> and <code>fusiontrees((b1, ‚Ä¶, bN‚ÇÇ), c)</code>, and with each of those, there is tensor data that takes the form of a multidimensional array, or, after reshaping, a matrix of size <code>(dim(codomain, (a1, ‚Ä¶, aN‚ÇÅ)), dim(domain, (b1, ‚Ä¶, bN‚ÇÇ))))</code>. Again, we can stack all such matrices with the same value of <code>f‚ÇÅ ‚àà fusiontrees((a1, ‚Ä¶, aN‚ÇÅ), c)</code> horizontally (as they all have the same number of rows), and with the same value of <code>f‚ÇÇ ‚àà fusiontrees((b1, ‚Ä¶, bN‚ÇÇ), c)</code> vertically (as they have the same number of columns). What emerges is a large matrix of size <code>(blockdim(codomain, c), blockdim(domain, c))</code> containing all the tensor data associated with the coupled sector <code>c</code>, where <code>blockdim(P, c) = sum(dim(P, s) * length(fusiontrees(s, c)) for s in sectors(P))</code> for some instance <code>P</code> of <code>ProductSpace</code>. The tensor implementation does not distinguish between abelian or non-abelian sectors and still stores these matrices concatenated in a <code>DenseVector</code>, where each individual block is accessible via <code>block(t, c)</code>.</p><p>At first sight, it might now be less clear what the relevance of this block is in relation to the full matrix representation of the tensor map, where the symmetry is not exploited. The essential interpretation is still the same. Schur&#39;s lemma now tells that there is a unitary basis transform which makes this matrix representation block diagonal, more specifically, of the form <span>$‚®Å_{c} B_c ‚äó ùüô_{c}$</span>, where <span>$B_c$</span> denotes <code>block(t, c)</code> and <span>$ùüô_{c}$</span> is an identity matrix of size <code>(dim(c), dim(c))</code>. The reason for this extra identity is that the group representation is recoupled to act as <span>$‚®Å_{c} ùüô ‚äó u_c(g)$</span> for all <span>$g ‚àà \mathsf{I}$</span>, with <span>$u_c(g)$</span> the matrix representation of group element <span>$g$</span> according to the irrep <span>$c$</span>. In the abelian case, <code>dim(c) == 1</code>, i.e. all irreducible representations are one-dimensional and Schur&#39;s lemma only dictates that all off-diagonal blocks are zero. However, in this case the basis transform to the block diagonal representation is not simply a permutation matrix, but a more general unitary matrix composed of the different fusion trees. Indeed, let us denote the fusion trees <code>f‚ÇÅ ‚àà fusiontrees((a1, ‚Ä¶, aN‚ÇÅ), c)</code> as <span>$X^{a_1, ‚Ä¶, a_{N‚ÇÅ}}_{c,Œ±}$</span> where <span>$Œ± = (e_1, ‚Ä¶, e_{N_1-2}; Œº‚ÇÅ, ‚Ä¶, Œº_{N_1-1})$</span> is a collective label for the internal sectors <code>e</code> and the vertex degeneracy labels <code>Œº</code> of a generic fusion tree, as discussed in the <a href="@ref ss_fusiontrees">corresponding section</a>. The tensor is then represented as</p><img src="../img/tensor-storage.svg" alt="tensor storage" class="color-invertible"/><p>In this diagram, we have indicated how the tensor map can be rewritten in terms of a block diagonal matrix with a unitary matrix on its left and another unitary matrix (if domain and codomain are different) on its right. So the left and right matrices should actually have been drawn as squares. They represent the unitary basis transform. In this picture, red and white regions are zero. The center matrix is most easy to interpret. It is the block diagonal matrix <span>$‚®Å_{c} B_c ‚äó ùüô_{c}$</span> with diagonal blocks labeled by the coupled charge <code>c</code>, in this case it takes two values. Every single small square in between the dotted or dashed lines has size <span>$d_c √ó d_c$</span> and corresponds to a single element of <span>$B_c$</span>, tensored with the identity <span>$\mathrm{id}_c$</span>. Instead of <span>$B_c$</span>, a more accurate labelling is <span>$t^c_{(a_1 ‚Ä¶ a_{N‚ÇÅ})Œ±, (b_1 ‚Ä¶ b_{N‚ÇÇ})Œ≤}$</span> where <span>$Œ±$</span> labels different fusion trees from <span>$(a_1 ‚Ä¶ a_{N‚ÇÅ})$</span> to <span>$c$</span>. The dashed horizontal lines indicate regions corresponding to different fusion (actually splitting) trees, either because of different sectors <span>$(a_1 ‚Ä¶ a_{N‚ÇÅ})$</span> or different labels <span>$Œ±$</span> within the same sector. Similarly, the dashed vertical lines define the border between regions of different fusion trees from the domain to <code>c</code>, either because of different sectors <span>$(b_1 ‚Ä¶ b_{N‚ÇÇ})$</span> or a different label <span>$Œ≤$</span>.</p><p>To understand this better, we need to understand the basis transformation, e.g. on the left (codomain) side. In more detail, it is given by</p><img src="../img/tensor-unitary.svg" alt="tensor unitary" class="color-invertible"/><p>Indeed, remembering that <span>$V_i = ‚®Å_{a_i} R_{a_i} ‚äó ‚ÑÇ^{n_{a_i}}$</span> with <span>$R_{a_i}$</span> the representation space on which irrep <span>$a_i$</span> acts (with dimension <span>$\mathrm{dim}(a_i)$</span>), we find</p><p class="math-container">\[V_1 ‚äó ‚Ä¶ ‚äó V_{N_1} = ‚®Å_{a_1, ‚Ä¶, a_{N‚ÇÅ}} (R_{a_1} ‚äó ‚Ä¶ ‚äó R_{a_{N_1}}) ‚äó ‚ÑÇ^{n_{a_1} √ó ‚Ä¶ n_{a_{N_1}}}.\]</p><p>In the diagram above, the wiggly lines correspond to the direct sum over the different sectors <span>$(a_1, ‚Ä¶, a_{N‚ÇÅ})$</span>, there depicted taking three possible values <span>$(a‚Ä¶)$</span>, <span>$(a‚Ä¶)‚Ä≤$</span> and <span>$(a‚Ä¶)‚Ä≤‚Ä≤$</span>. The tensor product <span>$(R_{a_1} ‚äó ‚Ä¶ ‚äó R_{a_{N_1}}) ‚äó ‚ÑÇ^{n_{a_1} √ó ‚Ä¶ n_{a_{N_1}}}$</span> is depicted as <span>$(R_{a_1} ‚äó ‚Ä¶ ‚äó R_{a_{N_1}})^{‚äï n_{a_1} √ó ‚Ä¶ n_{a_{N_1}}}$</span>, i.e. as a direct sum of the spaces <span>$R_{(a‚Ä¶)} = (R_{a_1} ‚äó ‚Ä¶ ‚äó R_{a_{N_1}})$</span> according to the dotted horizontal lines, which repeat <span>$n_{(a‚Ä¶)} = n_{a_1} √ó ‚Ä¶ n_{a_{N_1}}$</span> times. In this particular example, <span>$n_{(a‚Ä¶)}=2$</span>, <span>$n_{(a‚Ä¶)&#39;}=3$</span> and <span>$n_{(a‚Ä¶)&#39;&#39;}=5$</span>. The thick vertical line represents the separation between the two different coupled sectors, denoted as <span>$c$</span> and <span>$c&#39;$</span>. Dashed vertical lines represent different ways of reaching the coupled sector, corresponding to different <code>Œ±</code>. In this example, the first sector <span>$(a‚Ä¶)$</span> has one fusion tree to <span>$c$</span>, labeled by <span>$c,Œ±$</span>, and two fusion trees to <span>$c&#39;$</span>, labeled by <span>$c&#39;,Œ±$</span> and <span>$c&#39;,Œ±&#39;$</span>. The second sector has only a fusion tree to <span>$c$</span>, labeled by <span>$c,Œ±&#39;$</span>. The third sector only has a fusion tree to <span>$c&#39;$</span>, labeld by <span>$c&#39;, Œ±&#39;&#39;$</span>. Finally then, because the fusion trees do not act on the spaces <span>$‚ÑÇ^{n_{a_1} √ó ‚Ä¶ n_{a_{N_1}}}$</span>, the dotted lines which represent the different <span>$n_{(a‚Ä¶)} = n_{a_1} √ó ‚Ä¶ n_{a_{N_1}}$</span> dimensions are also drawn vertically. In particular, for a given sector <span>$(a‚Ä¶)$</span> and a specific fusion tree <span>$X^{(a‚Ä¶)}_{c,Œ±} : R_{(a‚Ä¶)}‚ÜíR_c$</span>, the action is <span>$X^{(a‚Ä¶)}_{c,Œ±} ‚äó ùüô_{n_{(a‚Ä¶)}}$</span>, which corresponds to the diagonal green blocks in this drawing where the same matrix <span>$X^{(a‚Ä¶)}_{c,Œ±}$</span> (the fusion tree) is repeated along the diagonal. Note that the fusion tree is not a vector or single column, but a matrix with number of rows equal to <span>$\mathrm{dim}(R_{(a\ldots)}) = d_{a_1} d_{a_2} ‚Ä¶ d_{a_{N_1}}$</span> and number of columns equal to <span>$d_c$</span>. A similar interpretation can be given to the basis transform on the right, by taking its adjoint. In this particular example, it has two different combinations of sectors <span>$(b‚Ä¶)$</span> and <span>$(b‚Ä¶)&#39;$</span>, where both have a single fusion tree to <span>$c$</span> as well as to <span>$c&#39;$</span>, and <span>$n_{(b‚Ä¶)}=2$</span>, <span>$n_{(b‚Ä¶)&#39;}=3$</span>.</p><p>Note that we never explicitly store or act with the basis transformations on the left and the right. For composing tensor maps (i.e. multiplying them), these basis transforms just cancel, whereas for tensor factorizations they just go through trivially. They transform non-trivially when reshuffling the tensor indices, both within or in between the domain and codomain. For this, however, we can completely rely on the manipulations of fusion trees to implicitly compute the effect of the basis transform and construct the new blocks <span>$B_c$</span> that result with respect to the new basis.</p><p>Hence, as before, we only store the diagonal blocks <span>$B_c$</span> of size <code>(blockdim(codomain(t), c), blockdim(domain(t), c))</code> as a <code>DenseMatrix</code>, accessible via <code>block(t, c)</code>. Within this matrix, there are regions of the form <code>view(block(t, c), m‚ÇÅ:m‚ÇÇ, n‚ÇÅ:n‚ÇÇ)</code> that correspond to the data <span>$t^c_{(a_1 ‚Ä¶ a_{N‚ÇÅ})Œ±, (b_1 ‚Ä¶ b_{N‚ÇÇ})Œ≤}$</span> associated with a pair of fusion trees <span>$X^{(a_1 ‚Ä¶ a_{N‚ÇÅ})}_{c,Œ±}$</span> and <span>$X^{(b_1 ‚Ä¶ b_{N‚ÇÇ})}_{c,Œ≤}$</span>, henceforth again denoted as <code>f‚ÇÅ</code> and <code>f‚ÇÇ</code>, with <code>f‚ÇÅ.coupled == f‚ÇÇ.coupled == c</code>. The ranges where this subblock is living are managed within the tensor implementation, and these subblocks can be accessed via <code>t[f‚ÇÅ, f‚ÇÇ]</code>, and is returned as a <code>StridedArray</code> of size <span>$n_{a_1} √ó n_{a_2} √ó ‚Ä¶ √ó n_{a_{N_1}} √ó n_{b_1} √ó ‚Ä¶ n_{b_{N‚ÇÇ}}$</span>, or in code, <code>(dim(V1, a1), dim(V2, a2), ‚Ä¶, dim(VN‚ÇÅ, aN‚ÇÅ), dim(W1, b1), ‚Ä¶, dim(WN‚ÇÇ, bN‚ÇÇ))</code>. While the implementation does not distinguish between <code>FusionStyle isa UniqueFusion</code> or <code>FusionStyle isa MultipleFusion</code>, in the former case the fusion tree is completely characterized by the uncoupled sectors, and so the subblocks can also be accessed as <code>t[(a1, ‚Ä¶, aN‚ÇÅ, b1, ‚Ä¶, bN‚ÇÇ)]</code>. When there is no symmetry at all, i.e.  <code>sectortype(t) == Trivial</code>, <code>t[]</code> returns the raw tensor data as a <code>StridedArray</code> of size <code>(dim(V1), ‚Ä¶, dim(VN‚ÇÅ), dim(W1), ‚Ä¶, dim(WN‚ÇÇ))</code>, whereas <code>block(t, Trivial())</code> returns the same data as a <code>DenseMatrix</code> of size <code>(dim(V1) * ‚Ä¶ * dim(VN‚ÇÅ), dim(W1) * ‚Ä¶ * dim(WN‚ÇÇ))</code>.</p><h2 id="ss_tensor_construction"><a class="docs-heading-anchor" href="#ss_tensor_construction">Constructing tensor maps and accessing tensor data</a><a id="ss_tensor_construction-1"></a><a class="docs-heading-anchor-permalink" href="#ss_tensor_construction" title="Permalink"></a></h2><p>Having learned how a tensor is represented and stored, we can now discuss how to create tensors and tensor maps. From hereon, we focus purely on the interface rather than the implementation.</p><h3 id="Random-and-uninitialized-tensor-maps"><a class="docs-heading-anchor" href="#Random-and-uninitialized-tensor-maps">Random and uninitialized tensor maps</a><a id="Random-and-uninitialized-tensor-maps-1"></a><a class="docs-heading-anchor-permalink" href="#Random-and-uninitialized-tensor-maps" title="Permalink"></a></h3><p>The most convenient set of constructors are those that construct tensors or tensor maps with random or uninitialized data. They take the form</p><pre><code class="language-julia hljs">f(codomain, domain = one(codomain))
f(eltype::Type{&lt;:Number}, codomain, domain = one(codomain))
TensorMap{eltype::Type{&lt;:Number}}(undef, codomain, domain = one(codomain))
Tensor{eltype::Type{&lt;:Number}}(undef, codomain)</code></pre><p>Here, <code>f</code> is any of the typical functions from Base that normally create arrays, namely <code>zeros</code>, <code>ones</code>, <code>rand</code>, <code>randn</code> and <code>Random.randexp</code>. Remember that <code>one(codomain)</code> is the empty <code>ProductSpace{S, 0}()</code>. The third and fourth calling syntax use the <code>UndefInitializer</code> from Julia Base and generates a <code>TensorMap</code> with unitialized data, which can thus contain <code>NaN</code>s.</p><p>In all of these constructors, the last two arguments can be replaced by <code>domain ‚Üí codomain</code> or <code>codomain ‚Üê domain</code>, where the arrows are obtained as <code>\rightarrow+TAB</code> and <code>\leftarrow+TAB</code> and create a <code>HomSpace</code> as explained in the section on <a href="../spaces/#ss_homspaces">Spaces of morphisms</a>. Some examples are perhaps in order</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; t1 = randn(‚ÑÇ^2 ‚äó ‚ÑÇ^3, ‚ÑÇ^2)</code><code class="nohighlight hljs ansi" style="display:block;">2√ó3‚Üê2 TensorMap{Float64, ComplexSpace, 2, 1, Vector{Float64}}:
 codomain: (‚ÑÇ^2 ‚äó ‚ÑÇ^3)
 domain: ‚äó(‚ÑÇ^2)
 blocks:
 * Trivial() =&gt; 6√ó2 reshape(view(::Vector{Float64}, 1:12), 6, 2) with eltype Float64:
  0.739452  -0.322894
  0.142486   1.15271
  2.01867    1.16832
  1.20281   -1.6197
 -1.42767   -0.00813217
 -0.616301   0.858798</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; t2 = zeros(Float32, ‚ÑÇ^2 ‚äó ‚ÑÇ^3 ‚Üê ‚ÑÇ^2)</code><code class="nohighlight hljs ansi" style="display:block;">2√ó3‚Üê2 TensorMap{Float32, ComplexSpace, 2, 1, Vector{Float32}}:
 codomain: (‚ÑÇ^2 ‚äó ‚ÑÇ^3)
 domain: ‚äó(‚ÑÇ^2)
 blocks:
 * Trivial() =&gt; 6√ó2 reshape(view(::Vector{Float32}, 1:12), 6, 2) with eltype Float32:
 0.0  0.0
 0.0  0.0
 0.0  0.0
 0.0  0.0
 0.0  0.0
 0.0  0.0</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; t3 = TensorMap{Float64}(undef, ‚ÑÇ^2 ‚Üí ‚ÑÇ^2 ‚äó ‚ÑÇ^3)</code><code class="nohighlight hljs ansi" style="display:block;">2√ó3‚Üê2 TensorMap{Float64, ComplexSpace, 2, 1, Vector{Float64}}:
 codomain: (‚ÑÇ^2 ‚äó ‚ÑÇ^3)
 domain: ‚äó(‚ÑÇ^2)
 blocks:
 * Trivial() =&gt; 6√ó2 reshape(view(::Vector{Float64}, 1:12), 6, 2) with eltype Float64:
 6.8985e-310   6.89858e-310
 6.8985e-310   6.89858e-310
 6.8985e-310   6.89858e-310
 6.8985e-310   6.8985e-310
 6.8985e-310   6.89858e-310
 6.89858e-310  6.89858e-310</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; domain(t1) == domain(t2) == domain(t3)</code><code class="nohighlight hljs ansi" style="display:block;">true</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; codomain(t1) == codomain(t2) == codomain(t3)</code><code class="nohighlight hljs ansi" style="display:block;">true</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; disp(x) = show(IOContext(Core.stdout, :compact=&gt;false), &quot;text/plain&quot;, trunc.(x; digits = 3));</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; t1[] |&gt; disp</code><code class="nohighlight hljs ansi" style="display:block;">2√ó3√ó2 StridedViews.StridedView{Float64, 3, GenericMemory{:not_atomic, Float64, Core.AddrSpace{Core}(0x00)}, typeof(identity)}:
[:, :, 1] =
 0.739  2.018  -1.427
 0.142  1.202  -0.616

[:, :, 2] =
 -0.322   1.168  -0.008
  1.152  -1.619   0.858</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; block(t1, Trivial()) |&gt; disp</code><code class="nohighlight hljs ansi" style="display:block;">6√ó2 Array{Float64, 2}:
  0.739  -0.322
  0.142   1.152
  2.018   1.168
  1.202  -1.619
 -1.427  -0.008
 -0.616   0.858</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; reshape(t1[], dim(codomain(t1)), dim(domain(t1))) |&gt; disp</code><code class="nohighlight hljs ansi" style="display:block;">6√ó2 Array{Float64, 2}:
  0.739  -0.322
  0.142   1.152
  2.018   1.168
  1.202  -1.619
 -1.427  -0.008
 -0.616   0.858</code></pre><p>Finally, all constructors can also be replaced by <code>Tensor(..., codomain)</code>, in which case the domain is assumed to be the empty <code>ProductSpace{S, 0}()</code>, which can easily be obtained as <code>one(codomain)</code>. Indeed, the empty product space is the unit object of the monoidal category, equivalent to the field of scalars <code>ùïú</code>, and thus the multiplicative identity (especially since <code>*</code> also acts as tensor product on vector spaces).</p><p>The matrices created by <code>f</code> are the matrices <span>$B_c$</span> discussed above, i.e. those returned by <code>block(t, c)</code>. Only numerical matrices of type <code>DenseMatrix</code> are accepted, which in practice just means Julia&#39;s intrinsic <code>Matrix{T}</code> for some <code>T &lt;: Number</code>. Ongoing work extends this to support for <code>CuMatrix</code> from <a href="https://github.com/JuliaGPU/CuArrays.jl">CuArrays.jl</a> to harness GPU computing power, and future work might include distributed arrays.</p><p>Support for static or sparse data is currently unavailable, and if it would be implemented, it would likely lead to new subtypes of <code>AbstractTensorMap</code> which are distinct from <code>TensorMap</code>. Future implementations of e.g. <code>SparseTensorMap</code> or <code>StaticTensorMap</code> could be useful.</p><h3 id="Tensor-maps-from-existing-data"><a class="docs-heading-anchor" href="#Tensor-maps-from-existing-data">Tensor maps from existing data</a><a id="Tensor-maps-from-existing-data-1"></a><a class="docs-heading-anchor-permalink" href="#Tensor-maps-from-existing-data" title="Permalink"></a></h3><p>To create a <code>TensorMap</code> with existing data, one can use the aforementioned form but with the function <code>f</code> replaced with the actual data, i.e. <code>TensorMap(data, codomain, domain)</code> or any of its equivalents.</p><p>Here, <code>data</code> can be of two types. It can be a dictionary (any <code>AbstractDict</code> subtype) which has blocksectors <code>c</code> of type <code>sectortype(codomain)</code> as keys, and the corresponding matrix blocks as value, i.e. <code>data[c]</code> is some <code>DenseMatrix</code> of size <code>(blockdim(codomain, c), blockdim(domain, c))</code>.</p><p>For those space types for which a <code>TensorMap</code> can be converted to a plain multidimensional array, the <code>data</code> can also be a general <code>DenseArray</code>, either of rank <code>N‚ÇÅ + N‚ÇÇ</code> and with matching size <code>(dims(codomain)..., dims(domain)...)</code>, or just as a <code>DenseMatrix</code> with size <code>(dim(codomain), dim(domain))</code>. This is true in particular if the sector type is <code>Trivial</code>, e.g. for <code>CartesianSpace</code> or <code>ComplexSpace</code>. Then the <code>data</code> array is just reshaped into matrix form and referred to as such in the resulting <code>TensorMap</code> instance. When <code>spacetype</code> is <code>GradedSpace</code>, the <code>TensorMap</code> constructor will try to reconstruct the tensor data such that the resulting tensor <code>t</code> satisfies <code>data == convert(Array, t)</code>. This might not be possible, if the data does not respect the symmetry structure. This procedure can be sketched using a simple physical example, namely the SWAP gate on two qubits,</p><p class="math-container">\[\begin{align*}
\mathrm{SWAP}: \mathbb{C}^2 \otimes \mathbb{C}^2 &amp; \to \mathbb{C}^2 \otimes \mathbb{C}^2\\
|i\rangle \otimes |j\rangle &amp;\mapsto |j\rangle \otimes |i\rangle.
\end{align*}\]</p><p>This operator can be rewritten in terms of the familiar Heisenberg exchange interaction <span>$\vec{S}_i \cdot \vec{S}_j$</span> as</p><p class="math-container">\[\mathrm{SWAP} = 2 \vec{S}_i \cdot \vec{S}_j + \frac{1}{2} ùüô,\]</p><p>where <span>$\vec{S} = (S^x, S^y, S^z)$</span> and the spin-1/2 generators of SU‚ÇÇ <span>$S^k$</span> are defined defined in terms of the <span>$2 \times 2$</span> Pauli matrices <span>$\sigma^k$</span> as <span>$S^k = \frac{1}{2}\sigma^k$</span>. The SWAP gate can be realized as a rank-4 <code>TensorMap</code> in the following way:</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; # encode the matrix elements of the swap gate into a rank-4 array, where the first two
       # indices correspond to the codomain and the last two indices correspond to the domain
       data = zeros(2,2,2,2)</code><code class="nohighlight hljs ansi" style="display:block;">2√ó2√ó2√ó2 Array{Float64, 4}:
[:, :, 1, 1] =
 0.0  0.0
 0.0  0.0

[:, :, 2, 1] =
 0.0  0.0
 0.0  0.0

[:, :, 1, 2] =
 0.0  0.0
 0.0  0.0

[:, :, 2, 2] =
 0.0  0.0
 0.0  0.0</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; # the swap gate then maps the last two indices on the first two in reversed order
       data[1,1,1,1] = data[2,2,2,2] = data[1,2,2,1] = data[2,1,1,2] = 1</code><code class="nohighlight hljs ansi" style="display:block;">1</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; V1 = ‚ÑÇ^2 # generic qubit hilbert space</code><code class="nohighlight hljs ansi" style="display:block;">‚ÑÇ^2</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; t1 = TensorMap(data, V1 ‚äó V1, V1 ‚äó V1)</code><code class="nohighlight hljs ansi" style="display:block;">2√ó2‚Üê2√ó2 TensorMap{Float64, ComplexSpace, 2, 2, Vector{Float64}}:
 codomain: (‚ÑÇ^2 ‚äó ‚ÑÇ^2)
 domain: (‚ÑÇ^2 ‚äó ‚ÑÇ^2)
 blocks:
 * Trivial() =&gt; 4√ó4 reshape(view(::Vector{Float64}, 1:16), 4, 4) with eltype Float64:
 1.0  0.0  0.0  0.0
 0.0  0.0  1.0  0.0
 0.0  1.0  0.0  0.0
 0.0  0.0  0.0  1.0</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; V2 = SU2Space(1/2=&gt;1) # hilbert space of an actual spin-1/2 particle, respecting symmetry</code><code class="nohighlight hljs ansi" style="display:block;">Rep[SU‚ÇÇ](‚Ä¶) of dim 2:
 1/2 =&gt; 1</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; t2 = TensorMap(data, V2 ‚äó V2, V2 ‚äó V2)</code><code class="nohighlight hljs ansi" style="display:block;">2√ó2‚Üê2√ó2 TensorMap{Float64, Rep[SU‚ÇÇ], 2, 2, Vector{Float64}}:
 codomain: (Rep[SU‚ÇÇ](1/2 =&gt; 1) ‚äó Rep[SU‚ÇÇ](1/2 =&gt; 1))
 domain: (Rep[SU‚ÇÇ](1/2 =&gt; 1) ‚äó Rep[SU‚ÇÇ](1/2 =&gt; 1))
 blocks:
 * Irrep[SU‚ÇÇ](0) =&gt; 1√ó1 reshape(view(::Vector{Float64}, 1:1), 1, 1) with eltype Float64:
 -1.0000000000000002

 * Irrep[SU‚ÇÇ](1) =&gt; 1√ó1 reshape(view(::Vector{Float64}, 2:2), 1, 1) with eltype Float64:
 0.9999999999999997</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; V3 = U1Space(1/2=&gt;1,-1/2=&gt;1) # restricted space that only uses the `œÉ_z` rotation symmetry</code><code class="nohighlight hljs ansi" style="display:block;">Rep[U‚ÇÅ](‚Ä¶) of dim 2:
  1/2 =&gt; 1
 -1/2 =&gt; 1</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; t3 = TensorMap(data, V3 ‚äó V3, V3 ‚äó V3)</code><code class="nohighlight hljs ansi" style="display:block;">2√ó2‚Üê2√ó2 TensorMap{Float64, Rep[U‚ÇÅ], 2, 2, Vector{Float64}}:
 codomain: (Rep[U‚ÇÅ](1/2 =&gt; 1, -1/2 =&gt; 1) ‚äó Rep[U‚ÇÅ](1/2 =&gt; 1, -1/2 =&gt; 1))
 domain: (Rep[U‚ÇÅ](1/2 =&gt; 1, -1/2 =&gt; 1) ‚äó Rep[U‚ÇÅ](1/2 =&gt; 1, -1/2 =&gt; 1))
 blocks:
 * Irrep[U‚ÇÅ](0) =&gt; 2√ó2 reshape(view(::Vector{Float64}, 1:4), 2, 2) with eltype Float64:
 0.0  1.0
 1.0  0.0

 * Irrep[U‚ÇÅ](1) =&gt; 1√ó1 reshape(view(::Vector{Float64}, 5:5), 1, 1) with eltype Float64:
 1.0

 * Irrep[U‚ÇÅ](-1) =&gt; 1√ó1 reshape(view(::Vector{Float64}, 6:6), 1, 1) with eltype Float64:
 1.0</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; for (c,b) in blocks(t3)
           println(&quot;Data for block $c :&quot;)
           disp(b)
           println()
       end</code><code class="nohighlight hljs ansi" style="display:block;">Data for block Irrep[U‚ÇÅ](0) :
2√ó2 Array{Float64, 2}:
 0.0  1.0
 1.0  0.0
Data for block Irrep[U‚ÇÅ](1) :
1√ó1 Array{Float64, 2}:
 1.0
Data for block Irrep[U‚ÇÅ](-1) :
1√ó1 Array{Float64, 2}:
 1.0</code></pre><p>Hence, we recognize that the exchange interaction has eigenvalue <span>$-1$</span> in the coupled spin zero sector (<code>SU2Irrep(0)</code>), and eigenvalue <span>$+1$</span> in the coupled spin 1 sector (<code>SU2Irrep(1)</code>). Using <code>Irrep[U‚ÇÅ]</code> instead, we observe that both coupled charge <code>U1Irrep(+1)</code> and <code>U1Irrep(-1)</code> have eigenvalue <span>$+1$</span>. The coupled charge <code>U1Irrep(0)</code> sector is two-dimensional, and has an eigenvalue <span>$+1$</span> and an eigenvalue <span>$-1$</span>.</p><p>To construct the proper <code>data</code> in more complicated cases, one has to know where to find each sector in the range <code>1:dim(V)</code> of every index <code>i</code> with associated space <code>V</code>, as well as the internal structure of the representation space when the corresponding sector <code>c</code> has <code>dim(c) &gt; 1</code>, i.e. in the case of <code>FusionStyle(c) isa MultipleFusion</code>. Currently, the only non-abelian sectors are <code>Irrep[SU‚ÇÇ]</code> and <code>Irrep[CU‚ÇÅ]</code>, for which the internal structure is the natural one.</p><p>There are some tools available to facilitate finding the proper range of sector <code>c</code> in space <code>V</code>, namely <code>axes(V, c)</code>. This also works on a <code>ProductSpace</code>, with a tuple of sectors. An example</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; V = SU2Space(0=&gt;3, 1=&gt;2, 2=&gt;1)</code><code class="nohighlight hljs ansi" style="display:block;">Rep[SU‚ÇÇ](‚Ä¶) of dim 14:
 0 =&gt; 3
 1 =&gt; 2
 2 =&gt; 1</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; P = V ‚äó V ‚äó V</code><code class="nohighlight hljs ansi" style="display:block;">(Rep[SU‚ÇÇ](0 =&gt; 3, 1 =&gt; 2, 2 =&gt; 1) ‚äó Rep[SU‚ÇÇ](0 =&gt; 3, 1 =&gt; 2, 2 =&gt; 1) ‚äó Rep[SU‚ÇÇ](0 =&gt; 3, 1 =&gt; 2, 2 =&gt; 1))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; axes(P, (SU2Irrep(1), SU2Irrep(0), SU2Irrep(2)))</code><code class="nohighlight hljs ansi" style="display:block;">(4:9, 1:3, 10:14)</code></pre><p>Note that the length of the range is the degeneracy dimension of that sector, times the dimension of the internal representation space, i.e. the quantum dimension of that sector.</p><h3 id="Assigning-block-data-after-initialization"><a class="docs-heading-anchor" href="#Assigning-block-data-after-initialization">Assigning block data after initialization</a><a id="Assigning-block-data-after-initialization-1"></a><a class="docs-heading-anchor-permalink" href="#Assigning-block-data-after-initialization" title="Permalink"></a></h3><p>In order to avoid having to know the internal structure of each representation space to properly construct the full <code>data</code> array, it is often simpler to assign the block data directly after initializing an all zero <code>TensorMap</code> with the correct spaces. While this may seem more difficult at first sight since it requires knowing the exact entries associated to each valid combination of domain uncoupled sectors, coupled sector and codomain uncoupled sectors, this is often a far more natural procedure in practice.</p><p>A first option is to directly set the full matrix block for each coupled sector in the <code>TensorMap</code>. For the example with <span>$\mathsf{U}_1$</span> symmetry, this can be done as</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; t4 = zeros(V3 ‚äó V3, V3 ‚äó V3);</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; block(t4, U1Irrep(0)) .= [1 0; 0 1];</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; block(t4, U1Irrep(1)) .= [1;;];</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; block(t4, U1Irrep(-1)) .= [1;;];</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; for (c, b) in blocks(t4)
           println(&quot;Data for block $c :&quot;)
           disp(b)
           println()
       end</code><code class="nohighlight hljs ansi" style="display:block;">Data for block Irrep[U‚ÇÅ](0) :
2√ó2 Array{Float64, 2}:
 1.0  0.0
 0.0  1.0
Data for block Irrep[U‚ÇÅ](1) :
1√ó1 Array{Float64, 2}:
 1.0
Data for block Irrep[U‚ÇÅ](-1) :
1√ó1 Array{Float64, 2}:
 1.0</code></pre><p>While this indeed does not require considering the internal structure of the representation spaces, it still requires knowing the precise row and column indices corresponding to each set of uncoupled sectors in the codmain and domain respectively to correctly assign the nonzero entries in each block.</p><p>Perhaps the most natural way of constructing a particular <code>TensorMap</code> is to directly assign the data slices for each splitting - fusion tree pair using the <code>fusiontrees(::TensorMap)</code> method. This returns an iterator over all tuples <code>(f‚ÇÅ, f‚ÇÇ)</code> of splitting - fusion tree pairs corresponding to all ways in which the set of domain uncoupled sectors can fuse to a coupled sector and split back into the set of codomain uncoupled sectors. By directly setting the corresponding data slice <code>t[f‚ÇÅ, f‚ÇÇ]</code> of size <code>(dims(codomain(t), f‚ÇÅ.uncoupled)..., dims(domain(t), f‚ÇÇ.uncoupled)...)</code>, we can construct all the block data without worrying about the internal ordering of row and column indices in each block. In addition, the corresponding value of each fusion tree slice is often directly informed by the object we are trying to construct in the first place. For example, in order to construct the Heisenberg exchange interaction on two spin-1/2 particles <span>$i$</span> and <span>$j$</span> as an SU‚ÇÇ symmetric <code>TensorMap</code>, we can make use of the observation that</p><p class="math-container">\[\vec{S}_i \cdot \vec{S}_j = \frac{1}{2} \left( \left( \vec{S}_i \cdot \vec{S}_j \right)^2 - \vec{S}_i^2 - \vec{S}_j^2 \right).\]</p><p>Recalling some basic group theory, we know that the <a href="https://en.wikipedia.org/wiki/Representation_theory_of_SU(2)#The_Casimir_element">quadratic Casimir of SU‚ÇÇ</a>, <span>$\vec{S}^2$</span>, has a well-defined eigenvalue <span>$j(j+1)$</span> on every irrep of spin <span>$j$</span>. From the above expressions, we can therefore directly read off the eigenvalues of the SWAP gate in terms of this Casimir eigenvalue on the domain uncoupled sectors and the coupled sector. This gives us exactly the prescription we need to assign the data slice corresponding to each splitting - fusion tree pair:</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; C(s::SU2Irrep) = s.j * (s.j + 1)</code><code class="nohighlight hljs ansi" style="display:block;">C (generic function with 1 method)</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; t5 = zeros(V2 ‚äó V2, V2 ‚äó V2);</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; for (f‚ÇÅ, f‚ÇÇ) in fusiontrees(t5)
           t5[f‚ÇÅ, f‚ÇÇ] .= C(f‚ÇÇ.coupled) - C(f‚ÇÇ.uncoupled[1]) - C(f‚ÇÇ.uncoupled[2]) + 1/2
       end</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; for (c, b) in blocks(t5)
           println(&quot;Data for block $c :&quot;)
           disp(b)
           println()
       end</code><code class="nohighlight hljs ansi" style="display:block;">Data for block Irrep[SU‚ÇÇ](0) :
1√ó1 Array{Float64, 2}:
 -1.0
Data for block Irrep[SU‚ÇÇ](1) :
1√ó1 Array{Float64, 2}:
 1.0</code></pre><h3 id="Constructing-similar-tensors"><a class="docs-heading-anchor" href="#Constructing-similar-tensors">Constructing similar tensors</a><a id="Constructing-similar-tensors-1"></a><a class="docs-heading-anchor-permalink" href="#Constructing-similar-tensors" title="Permalink"></a></h3><p>A third way to construct a <code>TensorMap</code> instance is to use <code>Base.similar</code>, i.e.</p><pre><code class="language-julia hljs">similar(t [, T::Type{&lt;:Number}, codomain, domain])</code></pre><p>where <code>T</code> is a possibly different <code>eltype</code> for the tensor data, and <code>codomain</code> and <code>domain</code> optionally define a new codomain and domain for the resulting tensor. By default, these values just take the value from the input tensor <code>t</code>. The result will be a new <code>TensorMap</code> instance, with <code>undef</code> data, but whose data is stored in the same subtype of <code>DenseVector</code> (e.g. <code>Vector</code> or <code>CuVector</code> or ...) as <code>t</code>. In particular, this uses the methods <code>storagetype(t)</code> and <code>TensorKit.similarstoragetype(t, T)</code>.</p><h3 id="Special-purpose-constructors"><a class="docs-heading-anchor" href="#Special-purpose-constructors">Special purpose constructors</a><a id="Special-purpose-constructors-1"></a><a class="docs-heading-anchor-permalink" href="#Special-purpose-constructors" title="Permalink"></a></h3><p>Finally, there are methods <code>zero</code>, <code>one</code>, <code>id</code>, <code>isomorphism</code>, <code>unitary</code> and <code>isometry</code> to create specific new tensors. Tensor maps behave as vectors and can be added (if they have the same domain and codomain); <code>zero(t)</code> is the additive identity, i.e. a <code>TensorMap</code> instance where all entries are zero. For a <code>t::TensorMap</code> with <code>domain(t) == codomain(t)</code>, i.e. an endomorphism, <code>one(t)</code> creates the identity tensor, i.e. the identity under composition. As discussed in the section on <a href="../tensormanipulations/#ss_tensor_linalg">linear algebra operations</a>, we denote composition of tensor maps with the multiplication operator <code>*</code>, such that <code>one(t)</code> is the multiplicative identity. Similarly, it can be created as <code>id(V)</code> with <code>V</code> the relevant vector space, e.g. <code>one(t) == id(domain(t))</code>. The identity tensor is currently represented with dense data, and one can use <code>id(A::Type{&lt;:DenseVector}, V)</code> to specify the type of <code>DenseVector</code> (and its <code>eltype</code>), e.g. <code>A = Vector{Float64}</code>. Finally, it often occurs that we want to construct a specific isomorphism between two spaces that are isomorphic but not equal, and for which there is no canonical choice. Hereto, one can use the method <code>u = isomorphism([A::Type{&lt;:DenseVector}, ] codomain, domain)</code>, which will explicitly check that the domain and codomain are isomorphic, and return an error otherwise. Again, an optional first argument can be given to specify the specific type of <code>DenseVector</code> that is currently used to store the rather trivial data of this tensor. If <code>InnerProductStyle(u) &lt;: EuclideanProduct</code>, the same result can be obtained with the method <code>u = unitary([A::Type{&lt;:DenseVector}, ] codomain, domain)</code>. Note that reversing the domain and codomain yields the inverse morphism, which in the case of <code>EuclideanProduct</code> coincides with the adjoint morphism, i.e. <code>isomorphism(A, domain, codomain) == adjoint(u) == inv(u)</code>, where <code>inv</code> and <code>adjoint</code> will be further discussed <a href="../tensormanipulations/#ss_tensor_linalg">below</a>. Finally, if two spaces <code>V1</code> and <code>V2</code> are such that <code>V2</code> can be embedded in <code>V1</code>, i.e. there exists an inclusion with a left inverse, and furthermore they represent tensor products of some <code>ElementarySpace</code> with <code>EuclideanProduct</code>, the function <code>w = isometry([A::Type{&lt;:DenseMatrix}, ], V1, V2)</code> creates one specific isometric embedding, such that <code>adjoint(w) * w == id(V2)</code> and <code>w * adjoint(w)</code> is some hermitian idempotent (a.k.a. orthogonal projector) acting on <code>V1</code>. An error will be thrown if such a map cannot be constructed for the given domain and codomain.</p><p>Let&#39;s conclude this section with some examples with <code>GradedSpace</code>.</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; V1 = ‚Ñ§‚ÇÇSpace(0 =&gt; 3, 1 =&gt; 2)</code><code class="nohighlight hljs ansi" style="display:block;">Rep[‚Ñ§‚ÇÇ](‚Ä¶) of dim 5:
 0 =&gt; 3
 1 =&gt; 2</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; V2 = ‚Ñ§‚ÇÇSpace(0 =&gt; 2, 1 =&gt; 1)</code><code class="nohighlight hljs ansi" style="display:block;">Rep[‚Ñ§‚ÇÇ](‚Ä¶) of dim 3:
 0 =&gt; 2
 1 =&gt; 1</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; # First a `TensorMap{‚Ñ§‚ÇÇSpace, 1, 1}`
       m = randn(V1, V2)</code><code class="nohighlight hljs ansi" style="display:block;">5‚Üê3 TensorMap{Float64, Rep[‚Ñ§‚ÇÇ], 1, 1, Vector{Float64}}:
 codomain: ‚äó(Rep[‚Ñ§‚ÇÇ](0 =&gt; 3, 1 =&gt; 2))
 domain: ‚äó(Rep[‚Ñ§‚ÇÇ](0 =&gt; 2, 1 =&gt; 1))
 blocks:
 * Irrep[‚Ñ§‚ÇÇ](0) =&gt; 3√ó2 reshape(view(::Vector{Float64}, 1:6), 3, 2) with eltype Float64:
 -1.54174  0.807799
 -0.17348  1.07211
 -1.79689  0.462407

 * Irrep[‚Ñ§‚ÇÇ](1) =&gt; 2√ó1 reshape(view(::Vector{Float64}, 7:8), 2, 1) with eltype Float64:
  0.18744369351876713
 -0.5634453591765805</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; convert(Array, m) |&gt; disp</code><code class="nohighlight hljs ansi" style="display:block;">5√ó3 Array{Float64, 2}:
 -1.541  0.807   0.0
 -0.173  1.072   0.0
 -1.796  0.462   0.0
  0.0    0.0     0.187
  0.0    0.0    -0.563</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; # compare with:
       block(m, Irrep[‚Ñ§‚ÇÇ](0)) |&gt; disp</code><code class="nohighlight hljs ansi" style="display:block;">3√ó2 Array{Float64, 2}:
 -1.541  0.807
 -0.173  1.072
 -1.796  0.462</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; block(m, Irrep[‚Ñ§‚ÇÇ](1)) |&gt; disp</code><code class="nohighlight hljs ansi" style="display:block;">2√ó1 Array{Float64, 2}:
  0.187
 -0.563</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; # Now a `TensorMap{‚Ñ§‚ÇÇSpace, 2, 2}`
       t = randn(V1 ‚äó V1, V2 ‚äó V2&#39;)</code><code class="nohighlight hljs ansi" style="display:block;">5√ó5‚Üê3√ó3 TensorMap{Float64, Rep[‚Ñ§‚ÇÇ], 2, 2, Vector{Float64}}:
 codomain: (Rep[‚Ñ§‚ÇÇ](0 =&gt; 3, 1 =&gt; 2) ‚äó Rep[‚Ñ§‚ÇÇ](0 =&gt; 3, 1 =&gt; 2))
 domain: (Rep[‚Ñ§‚ÇÇ](0 =&gt; 2, 1 =&gt; 1) ‚äó Rep[‚Ñ§‚ÇÇ](0 =&gt; 2, 1 =&gt; 1)&#39;)
 blocks:
 * Irrep[‚Ñ§‚ÇÇ](0) =&gt; 13√ó5 reshape(view(::Vector{Float64}, 1:65), 13, 5) with eltype Float64:
 -0.380638    -0.710897    -1.75555    0.147294    1.01688
  0.00557772  -1.12637      0.290495   0.455647    0.72123
 -0.0105527   -0.00831499   0.67081    0.664661    0.220785
  ‚ãÆ
 -0.397893     0.354278    -0.136665   0.4182     -1.25861
  1.00075      0.193553     0.880964  -1.68774     0.584714
  0.273595    -0.260772    -1.05201    0.0940001  -0.690066

 * Irrep[‚Ñ§‚ÇÇ](1) =&gt; 12√ó4 reshape(view(::Vector{Float64}, 66:113), 12, 4) with eltype Float64:
  0.128814   0.378422   0.195344   1.55161
  1.45055   -2.16678    1.98154   -0.421512
  1.54948   -0.730864   1.64627   -1.13509
  ‚ãÆ
  0.731955   0.636384   0.199268   2.18402
  0.687849  -0.487194   0.158482  -0.957103
 -1.832     -2.21065   -0.652019   0.684483</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; (array = convert(Array, t)) |&gt; disp</code><code class="nohighlight hljs ansi" style="display:block;">5√ó5√ó3√ó3 Array{Float64, 4}:
[:, :, 1, 1] =
 -0.38   0.744  -1.875   0.0    0.0
  0.005  0.467   0.189   0.0    0.0
 -0.01   0.423  -0.349   0.0    0.0
  0.0    0.0     0.0     1.973  1.0
  0.0    0.0     0.0    -0.397  0.273

[:, :, 2, 1] =
 -0.71    1.046  -0.718   0.0     0.0
 -1.126  -0.348   1.246   0.0     0.0
 -0.008  -0.88    0.079   0.0     0.0
  0.0     0.0     0.0    -1.404   0.193
  0.0     0.0     0.0     0.354  -0.26

[:, :, 3, 1] =
 0.0    0.0     0.0    -1.29    0.731
 0.0    0.0     0.0     0.609   0.687
 0.0    0.0     0.0     0.233  -1.832
 0.128  1.549   2.27    0.0     0.0
 1.45   0.618  -0.097   0.0     0.0

[:, :, 1, 2] =
 -1.755  -0.356  -1.02    0.0     0.0
  0.29    2.32   -0.666   0.0     0.0
  0.67   -0.311  -0.952   0.0     0.0
  0.0     0.0     0.0     0.719   0.88
  0.0     0.0     0.0    -0.136  -1.052

[:, :, 2, 2] =
 0.147   0.584  -0.369   0.0     0.0
 0.455  -0.322   0.092   0.0     0.0
 0.664  -0.821   1.127   0.0     0.0
 0.0     0.0     0.0    -0.669  -1.687
 0.0     0.0     0.0     0.418   0.094

[:, :, 3, 2] =
  0.0     0.0     0.0    0.663   0.636
  0.0     0.0     0.0    0.573  -0.487
  0.0     0.0     0.0    0.95   -2.21
  0.378  -0.73   -1.382  0.0     0.0
 -2.166   1.015  -1.809  0.0     0.0

[:, :, 1, 3] =
 0.0    0.0     0.0    -0.72    0.199
 0.0    0.0     0.0     1.765   0.158
 0.0    0.0     0.0     1.855  -0.652
 0.195  1.646  -0.132   0.0     0.0
 1.981  0.415   0.564   0.0     0.0

[:, :, 2, 3] =
  0.0     0.0     0.0    -1.064   2.184
  0.0     0.0     0.0     1.742  -0.957
  0.0     0.0     0.0     0.547   0.684
  1.551  -1.135  -2.611   0.0     0.0
 -0.421  -0.11   -0.508   0.0     0.0

[:, :, 3, 3] =
 1.016   1.018  -1.464   0.0     0.0
 0.721  -0.406  -0.487   0.0     0.0
 0.22   -0.409  -0.458   0.0     0.0
 0.0     0.0     0.0    -0.947   0.584
 0.0     0.0     0.0    -1.258  -0.69</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; d1 = dim(codomain(t))</code><code class="nohighlight hljs ansi" style="display:block;">25</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; d2 = dim(domain(t))</code><code class="nohighlight hljs ansi" style="display:block;">9</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; (matrix = reshape(array, d1, d2)) |&gt; disp</code><code class="nohighlight hljs ansi" style="display:block;">25√ó9 Array{Float64, 2}:
 -0.38   -0.71    0.0    -1.755   0.147   0.0     0.0     0.0     1.016
  0.005  -1.126   0.0     0.29    0.455   0.0     0.0     0.0     0.721
 -0.01   -0.008   0.0     0.67    0.664   0.0     0.0     0.0     0.22
  0.0     0.0     0.128   0.0     0.0     0.378   0.195   1.551   0.0
  0.0     0.0     1.45    0.0     0.0    -2.166   1.981  -0.421   0.0
  0.744   1.046   0.0    -0.356   0.584   0.0     0.0     0.0     1.018
  0.467  -0.348   0.0     2.32   -0.322   0.0     0.0     0.0    -0.406
  0.423  -0.88    0.0    -0.311  -0.821   0.0     0.0     0.0    -0.409
  0.0     0.0     1.549   0.0     0.0    -0.73    1.646  -1.135   0.0
  0.0     0.0     0.618   0.0     0.0     1.015   0.415  -0.11    0.0
 -1.875  -0.718   0.0    -1.02   -0.369   0.0     0.0     0.0    -1.464
  0.189   1.246   0.0    -0.666   0.092   0.0     0.0     0.0    -0.487
 -0.349   0.079   0.0    -0.952   1.127   0.0     0.0     0.0    -0.458
  0.0     0.0     2.27    0.0     0.0    -1.382  -0.132  -2.611   0.0
  0.0     0.0    -0.097   0.0     0.0    -1.809   0.564  -0.508   0.0
  0.0     0.0    -1.29    0.0     0.0     0.663  -0.72   -1.064   0.0
  0.0     0.0     0.609   0.0     0.0     0.573   1.765   1.742   0.0
  0.0     0.0     0.233   0.0     0.0     0.95    1.855   0.547   0.0
  1.973  -1.404   0.0     0.719  -0.669   0.0     0.0     0.0    -0.947
 -0.397   0.354   0.0    -0.136   0.418   0.0     0.0     0.0    -1.258
  0.0     0.0     0.731   0.0     0.0     0.636   0.199   2.184   0.0
  0.0     0.0     0.687   0.0     0.0    -0.487   0.158  -0.957   0.0
  0.0     0.0    -1.832   0.0     0.0    -2.21   -0.652   0.684   0.0
  1.0     0.193   0.0     0.88   -1.687   0.0     0.0     0.0     0.584
  0.273  -0.26    0.0    -1.052   0.094   0.0     0.0     0.0    -0.69</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; (u = reshape(convert(Array, unitary(codomain(t), fuse(codomain(t)))), d1, d1)) |&gt; disp</code><code class="nohighlight hljs ansi" style="display:block;">25√ó25 Array{Float64, 2}:
 1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; (v = reshape(convert(Array, unitary(domain(t), fuse(domain(t)))), d2, d2)) |&gt; disp</code><code class="nohighlight hljs ansi" style="display:block;">9√ó9 Array{Float64, 2}:
 1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0
 0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0
 0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0
 0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; u&#39; * u ‚âà I ‚âà v&#39; * v</code><code class="nohighlight hljs ansi" style="display:block;">true</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; (u&#39; * matrix * v) |&gt; disp</code><code class="nohighlight hljs ansi" style="display:block;">25√ó9 Array{Float64, 2}:
 -0.38   -0.71   -1.755   0.147   1.016   0.0     0.0     0.0     0.0
  0.005  -1.126   0.29    0.455   0.721   0.0     0.0     0.0     0.0
 -0.01   -0.008   0.67    0.664   0.22    0.0     0.0     0.0     0.0
  0.744   1.046  -0.356   0.584   1.018   0.0     0.0     0.0     0.0
  0.467  -0.348   2.32   -0.322  -0.406   0.0     0.0     0.0     0.0
  0.423  -0.88   -0.311  -0.821  -0.409   0.0     0.0     0.0     0.0
 -1.875  -0.718  -1.02   -0.369  -1.464   0.0     0.0     0.0     0.0
  0.189   1.246  -0.666   0.092  -0.487   0.0     0.0     0.0     0.0
 -0.349   0.079  -0.952   1.127  -0.458   0.0     0.0     0.0     0.0
  1.973  -1.404   0.719  -0.669  -0.947   0.0     0.0     0.0     0.0
 -0.397   0.354  -0.136   0.418  -1.258   0.0     0.0     0.0     0.0
  1.0     0.193   0.88   -1.687   0.584   0.0     0.0     0.0     0.0
  0.273  -0.26   -1.052   0.094  -0.69    0.0     0.0     0.0     0.0
  0.0     0.0     0.0     0.0     0.0     0.128   0.378   0.195   1.551
  0.0     0.0     0.0     0.0     0.0     1.45   -2.166   1.981  -0.421
  0.0     0.0     0.0     0.0     0.0     1.549  -0.73    1.646  -1.135
  0.0     0.0     0.0     0.0     0.0     0.618   1.015   0.415  -0.11
  0.0     0.0     0.0     0.0     0.0     2.27   -1.382  -0.132  -2.611
  0.0     0.0     0.0     0.0     0.0    -0.097  -1.809   0.564  -0.508
  0.0     0.0     0.0     0.0     0.0    -1.29    0.663  -0.72   -1.064
  0.0     0.0     0.0     0.0     0.0     0.609   0.573   1.765   1.742
  0.0     0.0     0.0     0.0     0.0     0.233   0.95    1.855   0.547
  0.0     0.0     0.0     0.0     0.0     0.731   0.636   0.199   2.184
  0.0     0.0     0.0     0.0     0.0     0.687  -0.487   0.158  -0.957
  0.0     0.0     0.0     0.0     0.0    -1.832  -2.21   -0.652   0.684</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; # compare with:
       block(t, Z2Irrep(0)) |&gt; disp</code><code class="nohighlight hljs ansi" style="display:block;">13√ó5 Array{Float64, 2}:
 -0.38   -0.71   -1.755   0.147   1.016
  0.005  -1.126   0.29    0.455   0.721
 -0.01   -0.008   0.67    0.664   0.22
  0.744   1.046  -0.356   0.584   1.018
  0.467  -0.348   2.32   -0.322  -0.406
  0.423  -0.88   -0.311  -0.821  -0.409
 -1.875  -0.718  -1.02   -0.369  -1.464
  0.189   1.246  -0.666   0.092  -0.487
 -0.349   0.079  -0.952   1.127  -0.458
  1.973  -1.404   0.719  -0.669  -0.947
 -0.397   0.354  -0.136   0.418  -1.258
  1.0     0.193   0.88   -1.687   0.584
  0.273  -0.26   -1.052   0.094  -0.69</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; block(t, Z2Irrep(1)) |&gt; disp</code><code class="nohighlight hljs ansi" style="display:block;">12√ó4 Array{Float64, 2}:
  0.128   0.378   0.195   1.551
  1.45   -2.166   1.981  -0.421
  1.549  -0.73    1.646  -1.135
  0.618   1.015   0.415  -0.11
  2.27   -1.382  -0.132  -2.611
 -0.097  -1.809   0.564  -0.508
 -1.29    0.663  -0.72   -1.064
  0.609   0.573   1.765   1.742
  0.233   0.95    1.855   0.547
  0.731   0.636   0.199   2.184
  0.687  -0.487   0.158  -0.957
 -1.832  -2.21   -0.652   0.684</code></pre><p>Here, we illustrated some additional concepts. Firstly, note that we convert a <code>TensorMap</code> to an <code>Array</code>. This only works when <code>sectortype(t)</code> supports <code>fusiontensor</code>, and in particular when <code>BraidingStyle(sectortype(t)) == Bosonic()</code>, e.g. the case of trivial tensors (the category <span>$\mathbf{Vect}$</span>) and group representations (the category <span>$\mathbf{Rep}_{\mathsf{G}}$</span>, which can be interpreted as a subcategory of <span>$\mathbf{Vect}$</span>). Here, we are in this case with <span>$\mathsf{G} = ‚Ñ§‚ÇÇ$</span>. For a <code>TensorMap{S, 1, 1}</code>, the blocks directly correspond to the diagonal blocks in the block diagonal structure of its representation as an <code>Array</code>, there is no basis transform in between. This is no longer the case for <code>TensorMap{S, N‚ÇÅ, N‚ÇÇ}</code> with different values of <code>N‚ÇÅ</code> and <code>N‚ÇÇ</code>. Here, we use the operation <code>fuse(V)</code>, which creates an <code>ElementarySpace</code> which is isomorphic to a given space <code>V</code> (of type <code>ProductSpace</code> or <code>ElementarySpace</code>). The specific map between those two spaces constructed using the specific method <code>unitary</code> implements precisely the basis change from the product basis to the coupled basis. In this case, for a group <code>G</code> with <code>FusionStyle(Irrep[G]) isa UniqueFusion</code>, it is a permutation matrix. Specifically choosing <code>V</code> equal to the codomain and domain of <code>t</code>, we can construct the explicit basis transforms that bring <code>t</code> into block diagonal form.</p><p>Let&#39;s repeat the same exercise for <code>I = Irrep[SU‚ÇÇ]</code>, which has <code>FusionStyle(I) isa MultipleFusion</code>.</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; V1 = SU‚ÇÇSpace(0 =&gt; 2, 1 =&gt; 1)</code><code class="nohighlight hljs ansi" style="display:block;">Rep[SU‚ÇÇ](‚Ä¶) of dim 5:
 0 =&gt; 2
 1 =&gt; 1</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; V2 = SU‚ÇÇSpace(0 =&gt; 1, 1 =&gt; 1)</code><code class="nohighlight hljs ansi" style="display:block;">Rep[SU‚ÇÇ](‚Ä¶) of dim 4:
 0 =&gt; 1
 1 =&gt; 1</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; # First a `TensorMap{SU‚ÇÇSpace, 1, 1}`
       m = randn(V1, V2)</code><code class="nohighlight hljs ansi" style="display:block;">5‚Üê4 TensorMap{Float64, Rep[SU‚ÇÇ], 1, 1, Vector{Float64}}:
 codomain: ‚äó(Rep[SU‚ÇÇ](0 =&gt; 2, 1 =&gt; 1))
 domain: ‚äó(Rep[SU‚ÇÇ](0 =&gt; 1, 1 =&gt; 1))
 blocks:
 * Irrep[SU‚ÇÇ](0) =&gt; 2√ó1 reshape(view(::Vector{Float64}, 1:2), 2, 1) with eltype Float64:
 -0.8190024994809967
  0.35135264018924983

 * Irrep[SU‚ÇÇ](1) =&gt; 1√ó1 reshape(view(::Vector{Float64}, 3:3), 1, 1) with eltype Float64:
 -0.072401417964788</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; convert(Array, m) |&gt; disp</code><code class="nohighlight hljs ansi" style="display:block;">5√ó4 Array{Float64, 2}:
 -0.819   0.0     0.0     0.0
  0.351   0.0     0.0     0.0
  0.0    -0.072   0.0     0.0
  0.0     0.0    -0.072   0.0
  0.0     0.0     0.0    -0.072</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; # compare with:
       block(m, Irrep[SU‚ÇÇ](0)) |&gt; disp</code><code class="nohighlight hljs ansi" style="display:block;">2√ó1 Array{Float64, 2}:
 -0.819
  0.351</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; block(m, Irrep[SU‚ÇÇ](1)) |&gt; disp</code><code class="nohighlight hljs ansi" style="display:block;">1√ó1 Array{Float64, 2}:
 -0.072</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; # Now a `TensorMap{SU‚ÇÇSpace, 2, 2}`
       t = randn(V1 ‚äó V1, V2 ‚äó V2&#39;)</code><code class="nohighlight hljs ansi" style="display:block;">5√ó5‚Üê4√ó4 TensorMap{Float64, Rep[SU‚ÇÇ], 2, 2, Vector{Float64}}:
 codomain: (Rep[SU‚ÇÇ](0 =&gt; 2, 1 =&gt; 1) ‚äó Rep[SU‚ÇÇ](0 =&gt; 2, 1 =&gt; 1))
 domain: (Rep[SU‚ÇÇ](0 =&gt; 1, 1 =&gt; 1) ‚äó Rep[SU‚ÇÇ](0 =&gt; 1, 1 =&gt; 1)&#39;)
 blocks:
 * Irrep[SU‚ÇÇ](0) =&gt; 5√ó2 reshape(view(::Vector{Float64}, 1:10), 5, 2) with eltype Float64:
  0.416351  -1.73807
 -0.164552  -0.972234
  0.637382  -0.417859
 -0.161511   1.68545
  0.169263  -0.929595

 * Irrep[SU‚ÇÇ](1) =&gt; 5√ó3 reshape(view(::Vector{Float64}, 11:25), 5, 3) with eltype Float64:
 -0.0283765   0.209915  -0.0647674
  0.099784    0.946485  -1.42108
  2.138      -0.890833   2.40327
 -0.628555    2.22695    1.90102
  1.77672     0.333002  -0.449442

 * Irrep[SU‚ÇÇ](2) =&gt; 1√ó1 reshape(view(::Vector{Float64}, 26:26), 1, 1) with eltype Float64:
 1.1752750705050323</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; (array = convert(Array, t)) |&gt; disp</code><code class="nohighlight hljs ansi" style="display:block;">5√ó5√ó4√ó4 Array{Float64, 4}:
[:, :, 1, 1] =
  0.416   0.637  0.0     0.0    0.0
 -0.164  -0.161  0.0     0.0    0.0
  0.0     0.0    0.0     0.0    0.097
  0.0     0.0    0.0    -0.097  0.0
  0.0     0.0    0.097   0.0    0.0

[:, :, 2, 1] =
  0.0    0.0     2.138  0.0    0.0
  0.0    0.0    -0.628  0.0    0.0
 -0.028  0.099   0.0    1.256  0.0
  0.0    0.0    -1.256  0.0    0.0
  0.0    0.0     0.0    0.0    0.0

[:, :, 3, 1] =
  0.0    0.0     0.0     2.138  0.0
  0.0    0.0     0.0    -0.628  0.0
  0.0    0.0     0.0     0.0    1.256
 -0.028  0.099   0.0     0.0    0.0
  0.0    0.0    -1.256   0.0    0.0

[:, :, 4, 1] =
  0.0    0.0    0.0   0.0     2.138
  0.0    0.0    0.0   0.0    -0.628
  0.0    0.0    0.0   0.0     0.0
  0.0    0.0    0.0   0.0     1.256
 -0.028  0.099  0.0  -1.256   0.0

[:, :, 1, 2] =
 0.0    0.0    0.0   0.0    -0.89
 0.0    0.0    0.0   0.0     2.226
 0.0    0.0    0.0   0.0     0.0
 0.0    0.0    0.0   0.0     0.235
 0.209  0.946  0.0  -0.235   0.0

[:, :, 2, 2] =
 -1.003  -0.241  0.0   1.699   0.0
 -0.561   0.973  0.0   1.344   0.0
  0.0     0.0    0.0   0.0    -0.338
 -0.045  -1.004  0.0   0.701   0.0
  0.0     0.0    0.11  0.0     0.0

[:, :, 3, 2] =
  0.0     0.0    0.0  0.0    1.699
  0.0     0.0    0.0  0.0    1.344
  0.0     0.0    0.0  0.0    0.0
  0.0     0.0    0.0  0.0    0.362
 -0.045  -1.004  0.0  0.812  0.0

[:, :, 4, 2] =
 0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  0.0
 0.0  0.0  0.0  0.0  1.175

[:, :, 1, 3] =
  0.0     0.0    0.0     0.89    0.0
  0.0     0.0    0.0    -2.226   0.0
  0.0     0.0    0.0     0.0    -0.235
 -0.209  -0.946  0.0     0.0     0.0
  0.0     0.0    0.235   0.0     0.0

[:, :, 2, 3] =
 0.0    0.0    -1.699   0.0    0.0
 0.0    0.0    -1.344   0.0    0.0
 0.045  1.004   0.0    -0.362  0.0
 0.0    0.0    -0.812   0.0    0.0
 0.0    0.0     0.0     0.0    0.0

[:, :, 3, 3] =
 -1.003  -0.241   0.0     0.0     0.0
 -0.561   0.973   0.0     0.0     0.0
  0.0     0.0     0.0     0.0    -0.701
  0.0     0.0     0.0    -0.473   0.0
  0.0     0.0    -0.701   0.0     0.0

[:, :, 4, 3] =
  0.0     0.0    0.0   0.0     1.699
  0.0     0.0    0.0   0.0     1.344
  0.0     0.0    0.0   0.0     0.0
  0.0     0.0    0.0   0.0    -0.812
 -0.045  -1.004  0.0  -0.362   0.0

[:, :, 1, 4] =
 0.0    0.0    -0.89   0.0    0.0
 0.0    0.0     2.226  0.0    0.0
 0.209  0.946   0.0    0.235  0.0
 0.0    0.0    -0.235  0.0    0.0
 0.0    0.0     0.0    0.0    0.0

[:, :, 2, 4] =
 0.0  0.0  0.0    0.0  0.0
 0.0  0.0  0.0    0.0  0.0
 0.0  0.0  1.175  0.0  0.0
 0.0  0.0  0.0    0.0  0.0
 0.0  0.0  0.0    0.0  0.0

[:, :, 3, 4] =
 0.0    0.0    -1.699  0.0    0.0
 0.0    0.0    -1.344  0.0    0.0
 0.045  1.004   0.0    0.812  0.0
 0.0    0.0     0.362  0.0    0.0
 0.0    0.0     0.0    0.0    0.0

[:, :, 4, 4] =
 -1.003  -0.241   0.0    -1.699  0.0
 -0.561   0.973   0.0    -1.344  0.0
  0.0     0.0     0.0     0.0    0.11
  0.045   1.004   0.0     0.701  0.0
  0.0     0.0    -0.338   0.0    0.0</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; d1 = dim(codomain(t))</code><code class="nohighlight hljs ansi" style="display:block;">25</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; d2 = dim(domain(t))</code><code class="nohighlight hljs ansi" style="display:block;">16</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; (matrix = reshape(array, d1, d2)) |&gt; disp</code><code class="nohighlight hljs ansi" style="display:block;">25√ó16 Array{Float64, 2}:
  0.416   0.0     0.0     0.0     0.0    -1.003   0.0    0.0     0.0     0.0    -1.003   0.0     0.0    0.0     0.0    -1.003
 -0.164   0.0     0.0     0.0     0.0    -0.561   0.0    0.0     0.0     0.0    -0.561   0.0     0.0    0.0     0.0    -0.561
  0.0    -0.028   0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.045   0.0     0.0     0.209  0.0     0.045   0.0
  0.0     0.0    -0.028   0.0     0.0    -0.045   0.0    0.0    -0.209   0.0     0.0     0.0     0.0    0.0     0.0     0.045
  0.0     0.0     0.0    -0.028   0.209   0.0    -0.045  0.0     0.0     0.0     0.0    -0.045   0.0    0.0     0.0     0.0
  0.637   0.0     0.0     0.0     0.0    -0.241   0.0    0.0     0.0     0.0    -0.241   0.0     0.0    0.0     0.0    -0.241
 -0.161   0.0     0.0     0.0     0.0     0.973   0.0    0.0     0.0     0.0     0.973   0.0     0.0    0.0     0.0     0.973
  0.0     0.099   0.0     0.0     0.0     0.0     0.0    0.0     0.0     1.004   0.0     0.0     0.946  0.0     1.004   0.0
  0.0     0.0     0.099   0.0     0.0    -1.004   0.0    0.0    -0.946   0.0     0.0     0.0     0.0    0.0     0.0     1.004
  0.0     0.0     0.0     0.099   0.946   0.0    -1.004  0.0     0.0     0.0     0.0    -1.004   0.0    0.0     0.0     0.0
  0.0     2.138   0.0     0.0     0.0     0.0     0.0    0.0     0.0    -1.699   0.0     0.0    -0.89   0.0    -1.699   0.0
  0.0    -0.628   0.0     0.0     0.0     0.0     0.0    0.0     0.0    -1.344   0.0     0.0     2.226  0.0    -1.344   0.0
  0.0     0.0     0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0     0.0     0.0     0.0    1.175   0.0     0.0
  0.0    -1.256   0.0     0.0     0.0     0.0     0.0    0.0     0.0    -0.812   0.0     0.0    -0.235  0.0     0.362   0.0
  0.097   0.0    -1.256   0.0     0.0     0.11    0.0    0.0     0.235   0.0    -0.701   0.0     0.0    0.0     0.0    -0.338
  0.0     0.0     2.138   0.0     0.0     1.699   0.0    0.0     0.89    0.0     0.0     0.0     0.0    0.0     0.0    -1.699
  0.0     0.0    -0.628   0.0     0.0     1.344   0.0    0.0    -2.226   0.0     0.0     0.0     0.0    0.0     0.0    -1.344
  0.0     1.256   0.0     0.0     0.0     0.0     0.0    0.0     0.0    -0.362   0.0     0.0     0.235  0.0     0.812   0.0
 -0.097   0.0     0.0     0.0     0.0     0.701   0.0    0.0     0.0     0.0    -0.473   0.0     0.0    0.0     0.0     0.701
  0.0     0.0     0.0    -1.256  -0.235   0.0     0.812  0.0     0.0     0.0     0.0    -0.362   0.0    0.0     0.0     0.0
  0.0     0.0     0.0     2.138  -0.89    0.0     1.699  0.0     0.0     0.0     0.0     1.699   0.0    0.0     0.0     0.0
  0.0     0.0     0.0    -0.628   2.226   0.0     1.344  0.0     0.0     0.0     0.0     1.344   0.0    0.0     0.0     0.0
  0.097   0.0     1.256   0.0     0.0    -0.338   0.0    0.0    -0.235   0.0    -0.701   0.0     0.0    0.0     0.0     0.11
  0.0     0.0     0.0     1.256   0.235   0.0     0.362  0.0     0.0     0.0     0.0    -0.812   0.0    0.0     0.0     0.0
  0.0     0.0     0.0     0.0     0.0     0.0     0.0    1.175   0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; (u = reshape(convert(Array, unitary(codomain(t), fuse(codomain(t)))), d1, d1)) |&gt; disp</code><code class="nohighlight hljs ansi" style="display:block;">25√ó25 Array{Float64, 2}:
 1.0  0.0  0.0  0.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.0    0.0  0.0    0.0    0.0    0.0
 0.0  1.0  0.0  0.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.0    0.0  0.0    0.0    0.0    0.0
 0.0  0.0  0.0  0.0   0.0    0.999  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.0    0.0  0.0    0.0    0.0    0.0
 0.0  0.0  0.0  0.0   0.0    0.0    0.999  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.0    0.0  0.0    0.0    0.0    0.0
 0.0  0.0  0.0  0.0   0.0    0.0    0.0    0.999  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.0    0.0  0.0    0.0    0.0    0.0
 0.0  0.0  1.0  0.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.0    0.0  0.0    0.0    0.0    0.0
 0.0  0.0  0.0  1.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.0    0.0  0.0    0.0    0.0    0.0
 0.0  0.0  0.0  0.0   0.0    0.0    0.0    0.0    0.999  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.0    0.0  0.0    0.0    0.0    0.0
 0.0  0.0  0.0  0.0   0.0    0.0    0.0    0.0    0.0    0.999  0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.0    0.0  0.0    0.0    0.0    0.0
 0.0  0.0  0.0  0.0   0.0    0.0    0.0    0.0    0.0    0.0    0.999  0.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.0    0.0  0.0    0.0    0.0    0.0
 0.0  0.0  0.0  0.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.999  0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.0    0.0  0.0    0.0    0.0    0.0
 0.0  0.0  0.0  0.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.999  0.0    0.0     0.0     0.0     0.0    0.0  0.0    0.0    0.0    0.0
 0.0  0.0  0.0  0.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.0    1.0  0.0    0.0    0.0    0.0
 0.0  0.0  0.0  0.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    -0.707   0.0     0.0    0.0  0.707  0.0    0.0    0.0
 0.0  0.0  0.0  0.0   0.577  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0    -0.707   0.0    0.0  0.0    0.408  0.0    0.0
 0.0  0.0  0.0  0.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.999  0.0    0.0    0.0    0.0     0.0     0.0     0.0    0.0  0.0    0.0    0.0    0.0
 0.0  0.0  0.0  0.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.999  0.0     0.0     0.0     0.0    0.0  0.0    0.0    0.0    0.0
 0.0  0.0  0.0  0.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.707   0.0     0.0    0.0  0.707  0.0    0.0    0.0
 0.0  0.0  0.0  0.0  -0.577  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.0    0.0  0.0    0.816  0.0    0.0
 0.0  0.0  0.0  0.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0    -0.707  0.0  0.0    0.0    0.707  0.0
 0.0  0.0  0.0  0.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.999  0.0    0.0    0.0     0.0     0.0     0.0    0.0  0.0    0.0    0.0    0.0
 0.0  0.0  0.0  0.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.999   0.0     0.0     0.0    0.0  0.0    0.0    0.0    0.0
 0.0  0.0  0.0  0.0   0.577  0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0     0.707   0.0    0.0  0.0    0.408  0.0    0.0
 0.0  0.0  0.0  0.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.707  0.0  0.0    0.0    0.707  0.0
 0.0  0.0  0.0  0.0   0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.0    0.0  0.0    0.0    0.0    1.0</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; (v = reshape(convert(Array, unitary(domain(t), fuse(domain(t)))), d2, d2)) |&gt; disp</code><code class="nohighlight hljs ansi" style="display:block;">16√ó16 Array{Float64, 2}:
 1.0  0.0    0.0    0.0    0.0    0.0     0.0    0.0     0.0     0.0    0.0    0.0     0.0     0.0     0.0    0.0
 0.0  0.0    0.999  0.0    0.0    0.0     0.0    0.0     0.0     0.0    0.0    0.0     0.0     0.0     0.0    0.0
 0.0  0.0    0.0    0.999  0.0    0.0     0.0    0.0     0.0     0.0    0.0    0.0     0.0     0.0     0.0    0.0
 0.0  0.0    0.0    0.0    0.999  0.0     0.0    0.0     0.0     0.0    0.0    0.0     0.0     0.0     0.0    0.0
 0.0  0.0    0.0    0.0    0.0    0.0     0.0    0.999   0.0     0.0    0.0    0.0     0.0     0.0     0.0    0.0
 0.0  0.577  0.0    0.0    0.0    0.0     0.0    0.0     0.0     0.707  0.0    0.0     0.0     0.408   0.0    0.0
 0.0  0.0    0.0    0.0    0.0    0.0     0.0    0.0     0.0     0.0    0.707  0.0     0.0     0.0     0.707  0.0
 0.0  0.0    0.0    0.0    0.0    0.0     0.0    0.0     0.0     0.0    0.0    0.0     0.0     0.0     0.0    0.999
 0.0  0.0    0.0    0.0    0.0    0.0    -0.999  0.0     0.0     0.0    0.0    0.0     0.0     0.0     0.0    0.0
 0.0  0.0    0.0    0.0    0.0    0.0     0.0    0.0    -0.707   0.0    0.0    0.0    -0.707   0.0     0.0    0.0
 0.0  0.577  0.0    0.0    0.0    0.0     0.0    0.0     0.0     0.0    0.0    0.0     0.0    -0.816   0.0    0.0
 0.0  0.0    0.0    0.0    0.0    0.0     0.0    0.0     0.0     0.0    0.707  0.0     0.0     0.0    -0.707  0.0
 0.0  0.0    0.0    0.0    0.0    0.999   0.0    0.0     0.0     0.0    0.0    0.0     0.0     0.0     0.0    0.0
 0.0  0.0    0.0    0.0    0.0    0.0     0.0    0.0     0.0     0.0    0.0    0.999   0.0     0.0     0.0    0.0
 0.0  0.0    0.0    0.0    0.0    0.0     0.0    0.0    -0.707   0.0    0.0    0.0     0.707   0.0     0.0    0.0
 0.0  0.577  0.0    0.0    0.0    0.0     0.0    0.0     0.0    -0.707  0.0    0.0     0.0     0.408   0.0    0.0</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; u&#39; * u ‚âà I ‚âà v&#39; * v</code><code class="nohighlight hljs ansi" style="display:block;">true</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; (u&#39; * matrix * v) |&gt; disp</code><code class="nohighlight hljs ansi" style="display:block;">25√ó16 Array{Float64, 2}:
  0.416  -1.738   0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0    0.0     0.0    -0.0     0.0    0.0
 -0.164  -0.972   0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0    0.0     0.0    -0.0     0.0    0.0
  0.637  -0.417   0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0     0.0    0.0
 -0.161   1.685   0.0     0.0     0.0     0.0     0.0     0.0     0.0    -0.0     0.0    0.0     0.0     0.0     0.0    0.0
  0.169  -0.929   0.0     0.0     0.0     0.0    -0.0     0.0     0.0     0.0     0.0    0.0     0.0    -0.0     0.0    0.0
  0.0     0.0    -0.028   0.0     0.0     0.209   0.0     0.0    -0.064   0.0     0.0    0.0     0.0     0.0     0.0    0.0
  0.0    -0.0     0.0    -0.028   0.0     0.0     0.209   0.0     0.0    -0.064   0.0    0.0     0.0     0.0     0.0    0.0
  0.0     0.0     0.0     0.0    -0.028   0.0     0.0     0.209   0.0     0.0    -0.064  0.0     0.0     0.0     0.0    0.0
  0.0     0.0     0.099   0.0     0.0     0.946   0.0     0.0    -1.421   0.0     0.0    0.0    -0.0     0.0     0.0    0.0
  0.0    -0.0     0.0     0.099   0.0     0.0     0.946   0.0     0.0    -1.421   0.0    0.0     0.0     0.0     0.0    0.0
  0.0     0.0     0.0     0.0     0.099   0.0     0.0     0.946   0.0     0.0    -1.421  0.0     0.0     0.0    -0.0    0.0
  0.0     0.0     2.138   0.0     0.0    -0.89    0.0     0.0     2.403   0.0     0.0    0.0     0.0     0.0     0.0    0.0
  0.0    -0.0     0.0     2.138   0.0     0.0    -0.89    0.0     0.0     2.403   0.0    0.0     0.0     0.0     0.0    0.0
  0.0     0.0     0.0     0.0     2.138   0.0     0.0    -0.89    0.0     0.0     2.403  0.0     0.0     0.0     0.0    0.0
  0.0     0.0    -0.628   0.0     0.0     2.226   0.0     0.0     1.901   0.0     0.0    0.0     0.0     0.0     0.0    0.0
  0.0    -0.0     0.0    -0.628   0.0     0.0     2.226   0.0     0.0     1.901   0.0    0.0     0.0     0.0     0.0    0.0
  0.0     0.0     0.0     0.0    -0.628   0.0     0.0     2.226   0.0     0.0     1.901  0.0     0.0     0.0     0.0    0.0
  0.0     0.0     1.776   0.0     0.0     0.333   0.0     0.0    -0.449   0.0     0.0    0.0    -0.0     0.0     0.0    0.0
 -0.0    -0.0     0.0     1.776   0.0     0.0     0.333   0.0     0.0    -0.449   0.0    0.0     0.0    -0.0     0.0    0.0
  0.0     0.0     0.0     0.0     1.776   0.0     0.0     0.333   0.0     0.0    -0.449  0.0     0.0     0.0    -0.0    0.0
  0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0    1.175   0.0     0.0     0.0    0.0
  0.0     0.0    -0.0     0.0     0.0     0.0     0.0     0.0    -0.0     0.0     0.0    0.0     1.175   0.0     0.0    0.0
 -0.0    -0.0     0.0    -0.0     0.0     0.0    -0.0     0.0     0.0    -0.0     0.0    0.0     0.0     1.175   0.0    0.0
  0.0     0.0     0.0     0.0    -0.0     0.0     0.0     0.0     0.0     0.0    -0.0    0.0     0.0     0.0     1.175  0.0
  0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0    0.0     0.0     0.0     0.0    1.175</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; # compare with:
       block(t, SU2Irrep(0)) |&gt; disp</code><code class="nohighlight hljs ansi" style="display:block;">5√ó2 Array{Float64, 2}:
  0.416  -1.738
 -0.164  -0.972
  0.637  -0.417
 -0.161   1.685
  0.169  -0.929</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; block(t, SU2Irrep(1)) |&gt; disp</code><code class="nohighlight hljs ansi" style="display:block;">5√ó3 Array{Float64, 2}:
 -0.028   0.209  -0.064
  0.099   0.946  -1.421
  2.138  -0.89    2.403
 -0.628   2.226   1.901
  1.776   0.333  -0.449</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; block(t, SU2Irrep(2)) |&gt; disp</code><code class="nohighlight hljs ansi" style="display:block;">1√ó1 Array{Float64, 2}:
 1.175</code></pre><p>Note that the basis transforms <code>u</code> and <code>v</code> are no longer permutation matrices, but are still unitary. Furthermore, note that they render the tensor block diagonal, but that now every element of the diagonal blocks labeled by <code>c</code> comes itself in a tensor product with an identity matrix of size <code>dim(c)</code>, i.e. <code>dim(SU2Irrep(1)) = 3</code> and <code>dim(SU2Irrep(2)) = 5</code>.</p><h2 id="ss_tensor_properties"><a class="docs-heading-anchor" href="#ss_tensor_properties">Tensor properties</a><a id="ss_tensor_properties-1"></a><a class="docs-heading-anchor-permalink" href="#ss_tensor_properties" title="Permalink"></a></h2><p>Given a <code>t::AbstractTensorMap{T, S, N‚ÇÅ, N‚ÇÇ}</code>, there are various methods to query its properties. The most important are clearly <code>codomain(t)</code> and <code>domain(t)</code>. For <code>t::AbstractTensor{S, N}</code>, i.e. <code>t::AbstractTensorMap{T, S, N, 0}</code>, we can use <code>space(t)</code> as synonym for <code>codomain(t)</code>. However, for a general <code>AbstractTensorMap</code> this has no meaning. However, we can query <code>space(t, i)</code>, the space associated with the <code>i</code>th index. For <code>i ‚àà 1:N‚ÇÅ</code>, this corresponds to <code>codomain(t, i) = codomain(t)[i]</code>. For <code>j = i-N‚ÇÅ ‚àà (1:N‚ÇÇ)</code>, this corresponds to <code>dual(domain(t, j)) = dual(domain(t)[j])</code>.</p><p>The total number of indices, i.e. <code>N‚ÇÅ + N‚ÇÇ</code>, is given by <code>numind(t)</code>, with <code>N‚ÇÅ == numout(t)</code> and <code>N‚ÇÇ == numin(t)</code>, the number of outgoing and incoming indices. There are also the unexported methods <code>TensorKit.codomainind(t)</code> and <code>TensorKit.domainind(t)</code> which return the tuples <code>(1, 2, ‚Ä¶, N‚ÇÅ)</code> and <code>(N‚ÇÅ+1, ‚Ä¶, N‚ÇÅ+N‚ÇÇ)</code>, and are useful for internal purposes. The type parameter <code>S &lt;: ElementarySpace</code> can be obtained as <code>spacetype(t)</code>; the corresponding sector can directly obtained as <code>sectortype(t)</code> and is <code>Trivial</code> when <code>S != GradedSpace</code>. The underlying field scalars of <code>S</code> can also directly be obtained as <code>field(t)</code>. This is different from <code>eltype(t)</code>, which returns the type of <code>Number</code> in the tensor data, i.e. the type parameter <code>T</code> in the (subtype of) <code>DenseVector{T}</code> in which the matrix blocks are stored. Note that during construction, a (one-time) warning is printed if <code>!(T ‚äÇ field(S))</code>. The specific <code>DenseVector{T}</code> subtype in which the tensor data is stored is obtained as <code>storagetype(t)</code>. Each of the methods <code>numind</code>, <code>numout</code>, <code>numin</code>, <code>TensorKit.codomainind</code>, <code>TensorKit.domainind</code>, <code>spacetype</code>, <code>sectortype</code>, <code>field</code>, <code>eltype</code> and <code>storagetype</code> work in the type domain as well, i.e. they are encoded in <code>typeof(t)</code>.</p><p>Finally, there are methods to probe the data, which we already encountered. <code>blocksectors(t)</code> returns an iterator over the different coupled sectors that can be obtained from fusing the uncoupled sectors available in the domain, but they must also be obtained from fusing the uncoupled sectors available in the codomain (i.e. it is the intersection of both <code>blocksectors(codomain(t))</code> and <code>blocksectors(domain(t))</code>). For a specific sector <code>c ‚àà blocksectors(t)</code>, <code>block(t, c)</code> returns the corresponding data. Both are obtained together with <code>blocks(t)</code>, which returns an iterator over the pairs <code>c =&gt; block(t, c)</code>. Furthermore, there is <code>fusiontrees(t)</code> which returns an iterator over splitting-fusion tree pairs <code>(f‚ÇÅ, f‚ÇÇ)</code>, for which the corresponding data is given by <code>t[f‚ÇÅ, f‚ÇÇ]</code> (i.e. using <code>Base.getindex</code>).</p><p>Let&#39;s again illustrate these methods with an example, continuing with the tensor <code>t</code> from the previous example</p><pre><code class="language-julia-repl hljs" style="display:block;">julia&gt; typeof(t)</code><code class="nohighlight hljs ansi" style="display:block;">TensorMap{Float64, GradedSpace{SU2Irrep, TensorKit.SortedVectorDict{SU2Irrep, Int64}}, 2, 2, Vector{Float64}}</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; codomain(t)</code><code class="nohighlight hljs ansi" style="display:block;">(Rep[SU‚ÇÇ](0 =&gt; 2, 1 =&gt; 1) ‚äó Rep[SU‚ÇÇ](0 =&gt; 2, 1 =&gt; 1))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; domain(t)</code><code class="nohighlight hljs ansi" style="display:block;">(Rep[SU‚ÇÇ](0 =&gt; 1, 1 =&gt; 1) ‚äó Rep[SU‚ÇÇ](0 =&gt; 1, 1 =&gt; 1)&#39;)</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; space(t,1)</code><code class="nohighlight hljs ansi" style="display:block;">Rep[SU‚ÇÇ](‚Ä¶) of dim 5:
 0 =&gt; 2
 1 =&gt; 1</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; space(t,2)</code><code class="nohighlight hljs ansi" style="display:block;">Rep[SU‚ÇÇ](‚Ä¶) of dim 5:
 0 =&gt; 2
 1 =&gt; 1</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; space(t,3)</code><code class="nohighlight hljs ansi" style="display:block;">Rep[SU‚ÇÇ](‚Ä¶)&#39; of dim 4:
 0 =&gt; 1
 1 =&gt; 1</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; space(t,4)</code><code class="nohighlight hljs ansi" style="display:block;">Rep[SU‚ÇÇ](‚Ä¶) of dim 4:
 0 =&gt; 1
 1 =&gt; 1</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; numind(t)</code><code class="nohighlight hljs ansi" style="display:block;">4</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; numout(t)</code><code class="nohighlight hljs ansi" style="display:block;">2</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; numin(t)</code><code class="nohighlight hljs ansi" style="display:block;">2</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; spacetype(t)</code><code class="nohighlight hljs ansi" style="display:block;">GradedSpace{SU2Irrep, TensorKit.SortedVectorDict{SU2Irrep, Int64}}</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; sectortype(t)</code><code class="nohighlight hljs ansi" style="display:block;">SU2Irrep</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; field(t)</code><code class="nohighlight hljs ansi" style="display:block;">‚ÑÇ</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; eltype(t)</code><code class="nohighlight hljs ansi" style="display:block;">Float64</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; storagetype(t)</code><code class="nohighlight hljs ansi" style="display:block;">Vector{Float64}<span class="sgr90"> (alias for Array{Float64, 1})</span></code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; blocksectors(t)</code><code class="nohighlight hljs ansi" style="display:block;">3-element Vector{SU2Irrep}:
 0
 1
 2</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; blocks(t)</code><code class="nohighlight hljs ansi" style="display:block;">blocks(::TensorMap{Float64, Rep[SU‚ÇÇ], 2, 2, Vector{Float64}}):
 * Irrep[SU‚ÇÇ](0) =&gt; 5√ó2 reshape(view(::Vector{Float64}, 1:10), 5, 2) with eltype Float64:
  0.416351  -1.73807
 -0.164552  -0.972234
  0.637382  -0.417859
 -0.161511   1.68545
  0.169263  -0.929595

 * Irrep[SU‚ÇÇ](1) =&gt; 5√ó3 reshape(view(::Vector{Float64}, 11:25), 5, 3) with eltype Float64:
 -0.0283765   0.209915  -0.0647674
  0.099784    0.946485  -1.42108
  2.138      -0.890833   2.40327
 -0.628555    2.22695    1.90102
  1.77672     0.333002  -0.449442

 * Irrep[SU‚ÇÇ](2) =&gt; 1√ó1 reshape(view(::Vector{Float64}, 26:26), 1, 1) with eltype Float64:
 1.1752750705050323</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; block(t, first(blocksectors(t)))</code><code class="nohighlight hljs ansi" style="display:block;">5√ó2 reshape(view(::Vector{Float64}, 1:10), 5, 2) with eltype Float64:
  0.416351  -1.73807
 -0.164552  -0.972234
  0.637382  -0.417859
 -0.161511   1.68545
  0.169263  -0.929595</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; fusiontrees(t)</code><code class="nohighlight hljs ansi" style="display:block;">14-element Vector{Tuple{FusionTree{SU2Irrep, 2, 0, 1}, FusionTree{SU2Irrep, 2, 0, 1}}}:
 (FusionTree{Irrep[SU‚ÇÇ]}((0, 0), 0, (false, false), ()), FusionTree{Irrep[SU‚ÇÇ]}((0, 0), 0, (false, true), ()))
 (FusionTree{Irrep[SU‚ÇÇ]}((1, 1), 0, (false, false), ()), FusionTree{Irrep[SU‚ÇÇ]}((0, 0), 0, (false, true), ()))
 (FusionTree{Irrep[SU‚ÇÇ]}((0, 0), 0, (false, false), ()), FusionTree{Irrep[SU‚ÇÇ]}((1, 1), 0, (false, true), ()))
 (FusionTree{Irrep[SU‚ÇÇ]}((1, 1), 0, (false, false), ()), FusionTree{Irrep[SU‚ÇÇ]}((1, 1), 0, (false, true), ()))
 (FusionTree{Irrep[SU‚ÇÇ]}((1, 0), 1, (false, false), ()), FusionTree{Irrep[SU‚ÇÇ]}((1, 0), 1, (false, true), ()))
 (FusionTree{Irrep[SU‚ÇÇ]}((0, 1), 1, (false, false), ()), FusionTree{Irrep[SU‚ÇÇ]}((1, 0), 1, (false, true), ()))
 (FusionTree{Irrep[SU‚ÇÇ]}((1, 1), 1, (false, false), ()), FusionTree{Irrep[SU‚ÇÇ]}((1, 0), 1, (false, true), ()))
 (FusionTree{Irrep[SU‚ÇÇ]}((1, 0), 1, (false, false), ()), FusionTree{Irrep[SU‚ÇÇ]}((0, 1), 1, (false, true), ()))
 (FusionTree{Irrep[SU‚ÇÇ]}((0, 1), 1, (false, false), ()), FusionTree{Irrep[SU‚ÇÇ]}((0, 1), 1, (false, true), ()))
 (FusionTree{Irrep[SU‚ÇÇ]}((1, 1), 1, (false, false), ()), FusionTree{Irrep[SU‚ÇÇ]}((0, 1), 1, (false, true), ()))
 (FusionTree{Irrep[SU‚ÇÇ]}((1, 0), 1, (false, false), ()), FusionTree{Irrep[SU‚ÇÇ]}((1, 1), 1, (false, true), ()))
 (FusionTree{Irrep[SU‚ÇÇ]}((0, 1), 1, (false, false), ()), FusionTree{Irrep[SU‚ÇÇ]}((1, 1), 1, (false, true), ()))
 (FusionTree{Irrep[SU‚ÇÇ]}((1, 1), 1, (false, false), ()), FusionTree{Irrep[SU‚ÇÇ]}((1, 1), 1, (false, true), ()))
 (FusionTree{Irrep[SU‚ÇÇ]}((1, 1), 2, (false, false), ()), FusionTree{Irrep[SU‚ÇÇ]}((1, 1), 2, (false, true), ()))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; f1, f2 = first(fusiontrees(t))</code><code class="nohighlight hljs ansi" style="display:block;">(FusionTree{Irrep[SU‚ÇÇ]}((0, 0), 0, (false, false), ()), FusionTree{Irrep[SU‚ÇÇ]}((0, 0), 0, (false, true), ()))</code><br/><code class="language-julia-repl hljs" style="display:block;">julia&gt; t[f1,f2]</code><code class="nohighlight hljs ansi" style="display:block;">2√ó2√ó1√ó1 StridedViews.StridedView{Float64, 4, Memory{Float64}, typeof(identity)}:
[:, :, 1, 1] =
  0.416351   0.637382
 -0.164552  -0.161511</code></pre><h2 id="ss_tensor_readwrite"><a class="docs-heading-anchor" href="#ss_tensor_readwrite">Reading and writing tensors: <code>Dict</code> conversion</a><a id="ss_tensor_readwrite-1"></a><a class="docs-heading-anchor-permalink" href="#ss_tensor_readwrite" title="Permalink"></a></h2><p>There are no custom or dedicated methods for reading, writing or storing <code>TensorMap</code>s, however, there is the possibility to convert a <code>t::AbstractTensorMap</code> into a <code>Dict</code>, simply as <code>convert(Dict, t)</code>. The backward conversion <code>convert(TensorMap, dict)</code> will return a tensor that is equal to <code>t</code>, i.e. <code>t == convert(TensorMap, convert(Dict, t))</code>.</p><p>This conversion relies on that the string represenation of objects such as <code>VectorSpace</code>, <code>FusionTree</code> or <code>Sector</code> should be such that it represents valid code to recreate the object. Hence, we store information about the domain and codomain of the tensor, and the sector associated with each data block, as a <code>String</code> obtained with <code>repr</code>. This provides the flexibility to still change the internal structure of such objects, without this breaking the ability to load older data files. The resulting dictionary can then be stored using any of the provided Julia packages such as <a href="https://github.com/JuliaIO/JLD.jl">JLD.jl</a>, <a href="https://github.com/JuliaIO/JLD2.jl">JLD2.jl</a>, <a href="https://github.com/JuliaIO/BSON.jl">BSON.jl</a>, <a href="https://github.com/JuliaIO/JSON.jl">JSON.jl</a>, ...</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../fusiontrees/">¬´ Fusion trees</a><a class="docs-footer-nextpage" href="../tensormanipulations/">Manipulating tensors ¬ª</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.17.0 on <span class="colophon-date" title="Wednesday 25 February 2026 15:54">Wednesday 25 February 2026</span>. Using Julia version 1.12.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
